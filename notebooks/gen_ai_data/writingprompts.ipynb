{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-18 17:06:22 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'story'],\n",
       "        num_rows: 272600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'story'],\n",
       "        num_rows: 15138\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['prompt', 'story'],\n",
       "        num_rows: 15620\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"euclaise/writingprompts\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ WP ] You 've finally managed to discover the...</td>\n",
       "      <td>So many times have I walked on ruins, the rema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ WP ] The moon is actually a giant egg , and ...</td>\n",
       "      <td>-Week 18 aboard the Depth Reaver, Circa 2023- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ WP ] You find a rip in time walking through ...</td>\n",
       "      <td>I was feckin' sloshed, mate. First time I ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ WP ] For years in your youth the same imagin...</td>\n",
       "      <td>“ No, no no no... ” She backed up and turned t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ WP ] You glance at your watch 10:34 am , rou...</td>\n",
       "      <td>There's a magical moment between wakefulness a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [ WP ] You 've finally managed to discover the...   \n",
       "1  [ WP ] The moon is actually a giant egg , and ...   \n",
       "2  [ WP ] You find a rip in time walking through ...   \n",
       "3  [ WP ] For years in your youth the same imagin...   \n",
       "4  [ WP ] You glance at your watch 10:34 am , rou...   \n",
       "\n",
       "                                               story  \n",
       "0  So many times have I walked on ruins, the rema...  \n",
       "1  -Week 18 aboard the Depth Reaver, Circa 2023- ...  \n",
       "2  I was feckin' sloshed, mate. First time I ever...  \n",
       "3  “ No, no no no... ” She backed up and turned t...  \n",
       "4  There's a magical moment between wakefulness a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dataset['train'].to_pandas(), dataset['validation'].to_pandas(), dataset['test'].to_pandas()])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt    0\n",
       "story     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [prompt[:6] for prompt in df['prompt'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[ WP ]', '[ IP ]', '[ CW ]', '[ EU ]', '[ OT ]', '[ TT ]',\n",
       "       '[ FF ]', '[ wp ]', '[ PI ]', '[ RF ]', '( WP )', '[ MP ]',\n",
       "       '[ Wp ]', '[ CC ]', 'Write ', '[ PM ]', \"You 'r\", 'You ar',\n",
       "       'Writin', '[ RE ]', '[ CS ]', '[ CONT', '( EU )', '[ cw ]',\n",
       "       '[ HP ]', '[ WS ]', 'A man ', 'In 100', '{ WP }', 'A dead',\n",
       "       '[ WP/E', '[ WR ]', '( CW )', 'The la', 'WP : A', 'All in',\n",
       "       'You wa', \"You 'v\", 'The ye', 'Daily ', '[ WP }', 'After ',\n",
       "       '`` Thi', 'You li', 'Make a', '[ Modp', 'Earth ', 'You ha',\n",
       "       'Magic ', '[ ff ]', 'Make m', '[ Writ', 'Pack a', 'At you',\n",
       "       '[ Eu ]', 'Last w', 'Last s', 'Descri', '[ WP/M', 'Gettin',\n",
       "       '[ WP ,', '[ WT ]', '[ NANO', 'The Fo', 'There ', '`` You',\n",
       "       'A worl', 'DAILY ', \"I 've \", '[ WP/C', \"I 'm a\", 'As you',\n",
       "       'Random', 'Prompt', 'Why is', 'Humans', 'A depr', '[ NSFW',\n",
       "       'You he', 'Create', 'Pictur', 'Shortl', 'In the', '[ [ WP',\n",
       "       'In an ', '( wp )', 'Two me', 'Give m', '`` A l', 'Meet a',\n",
       "       'A litt', 'The he', 'A chil', 'Open y', '[ eu ]', 'No hum',\n",
       "       'You lo', 'Aliens', '200 wo', 'Human ', 'You ca', 'The am',\n",
       "       '[ Bah ', 'Waitin', 'Tomorr', 'An imm', 'The zo', 'Creep ',\n",
       "       '{ EU }', 'A grea', \"It 's \", 'In thi', 'Six mo', '[ MOD ',\n",
       "       'Mankin', '{ wp }', 'On the', 'A KKK ', 'Four b', 'Everyo',\n",
       "       '[ Imag', '[ OFF ', 'Santa ', '[ ot ]', 'A hous', 'Listen',\n",
       "       'Just w', 'In a w', 'Every ', '`` It ', 'You an', 'Childr',\n",
       "       'A moun', 'A terr', 'A stor', 'It is ', '[ WP A', '( Wp )',\n",
       "       'A fasc', 'A char', 'While ', 'The wo', 'The ap', 'You di',\n",
       "       '`` Wel', 'A Barb', 'A conv', '`` Dud', 'A Heis', 'During',\n",
       "       'Whenev', '{ Wp }', '[ META', '[ Prom', 'One da', 'Start ',\n",
       "       'Your f', 'A woma', 'Terror', 'Someon', 'No lig', 'A dark',\n",
       "       'Everyb', 'Two ch', 'An int', 'An old', 'An inc', 'The Sh',\n",
       "       'WP - Y', 'Bank r', \"you 'r\", 'Hitler', 'And th', 'UPS ha',\n",
       "       'A knig', 'Your k', 'She ho', 'A trib', 'An 13 ', 'A grou',\n",
       "       '[ ip ]', 'A bori', 'Provid', '[ tt ]', '[ WP/W', 'Overpo',\n",
       "       'Next g', 'Nihili', 'Scient', 'Light ', '[ W.P ', '[ W P ',\n",
       "       'The He', 'Tag te', 'Telepo', 'Tell m', 'A youn', '[ CM ]',\n",
       "       'As he ', 'Due to', 'An abu', 'The de', 'An alc', 'The Vi',\n",
       "       'Your d', 'First ', 'You re', 'Facing', 'Comedy', 'Monste',\n",
       "       '7.6 bi', 'WP : Y', 'Need h', '( CC )', '`` The', 'WP : I',\n",
       "       'Waldo ', 'Two co', 'Two lo', 'Two ol', 'David ', 'Today ',\n",
       "       'Though', 'Two pe', 'Five y', 'As the', 'As one', \"Do n't\",\n",
       "       'The gi', 'Even i', 'Any st', '[ Cw ]', 'I the ', 'She sa',\n",
       "       '[ IP ,', 'I am d', 'She lo', 'Humani', 'Tell t', 'How do',\n",
       "       'The Ru', 'The en', 'Home a', 'You fi', 'A sket', 'A boy ',\n",
       "       '[ Wiri', '[ WP/I', 'Kim Jo', 'A grim', 'A mask', 'It sta',\n",
       "       '[ cc ]', 'The lo', 'Hogwar', 'Horror', 'You vi', 'The Be',\n",
       "       'Taking', 'I want', 'The Cu', 'An ant', 'The bl', 'An NSA',\n",
       "       'Forest', 'Establ', 'Willy ', 'When s', '[ CW ?', 'Short ',\n",
       "       'In a f', 'In a c', '[ EU ,', 'AlphaG', 'The Ki', 'The La',\n",
       "       'Natura', 'A spac', 'Imagin', '[ EU/W', 'Serial', 'Sleep ',\n",
       "       'Stress', '[ Esta', '[ FF/C', 'You go', '[ PP ]', 'Pick y',\n",
       "       'A bill', '`` A M', '`` A t', '[ prom', 'A Time', '[ RP ]',\n",
       "       'Just b', 'In whi', 'Inspir', 'Make u', 'A lone', '[ WP ;',\n",
       "       'What i', 'What w', 'WP : G', 'Change', 'NSFW [', 'Once u',\n",
       "       '200 ye', '`` Tha', 'News o', 'A pers', 'An exp', 'The pr',\n",
       "       'The sc', 'Explai', 'April ', 'Wp . T', 'God cr', 'An esc',\n",
       "       'Are th', 'Aperso', 'As a v', 'Devine', 'What D', 'Well-t',\n",
       "       'The fi', 'End a ', 'The mo', '`` If ', '`` Nob', '`` She',\n",
       "       '( FF )', 'end an', 'On you', '2050 .', '3 coll', 'But he',\n",
       "       'WP abo', 'Time t', 'Two ca', 'Upon r', \"What '\", 'Sherlo',\n",
       "       'Sittin', 'In a p', 'A war ', 'Someti', 'Stoich', 'Abando',\n",
       "       '[ CW }', 'I wish', 'IP : L', 'A vast', 'Story ', 'Stoppi',\n",
       "       'Tactic', 'The De', '[ CW/F', 'God is', 'God ma', 'God su',\n",
       "       'You ru', 'You sa', 'You in', 'An eld', 'The ``', 'A man/',\n",
       "       'In fro', 'It tur', 'Puttin', '[ OT -', 'A new ', 'Queen ',\n",
       "       '[ WP f', '[ WP/R', '[ WP/T', 'Satan ', 'Scents', 'Lookin',\n",
       "       'A grav', '[ WB ]', '[ WD ]', 'Of all', 'On a l', 'A cont',\n",
       "       'A clas', 'One ma', 'One ni', 'One wo', '[ WP/H', '[ mp ]',\n",
       "       '{ WP ]', '1 [ WP', '( no p', '{ OT }', \"'Unbek\", '`` I w',\n",
       "       '... Mo', 'a youn', 'you ar', '55-Wor', 'One mo', '`` But',\n",
       "       '`` Do ', '`` I a', '`` I d', '[ pm ]', 'Ms. Fr', 'Music ',\n",
       "       'A beau', 'A blin', 'A blon', 'A boun', '[ WP/O', '[ [ IP',\n",
       "       '`` Are', 'Origin', 'Over-e', 'Person', 'No-one', 'Nobody',\n",
       "       'Jesus ', 'A drug', 'A fame', 'A famo', 'A flic', 'A frie',\n",
       "       'A futu', '[ WP .', '[ rf ]', '[ wp/c', 'Lucid ', 'Make D',\n",
       "       'She ha', 'She wa', 'Slaver', 'A lazy', 'A mix ', 'A mode',\n",
       "       'A doct', '[ TEXT', '[ Meta', 'A supe', '[ EU :', '[ EU C',\n",
       "       '[ PI/C', '[ PW ]', 'Its th', 'Presid', 'Questi', 'A veng',\n",
       "       'AI are', '[ CC/P', '[ CW/W', 'A rebe', 'All st', 'Your m',\n",
       "       '[ /WP ', '[ CC }', 'You us', 'Achill', 'An agr', 'An ali',\n",
       "       'An all', 'An anc', 'An end', 'Ideali', 'Identi', 'If Har',\n",
       "       'In 30 ', 'In 509', 'That o', 'The A-', 'The Ai', 'You ma',\n",
       "       'An imp', 'An iro', 'Winter', 'Your a', 'Your c', 'How is',\n",
       "       'Hundre', 'I chal', 'I was ', 'Snow\\n', 'So how', 'Space ',\n",
       "       'Hermoi', 'Hi ! F', 'You , ', 'You aw', 'Anybod', 'As a t',\n",
       "       'As per', 'You ge', 'The Jo', 'The Le', 'Tell a', 'Tell u',\n",
       "       'The Sw', 'At som', 'Barack', 'Batman', 'Blanke', 'Botani',\n",
       "       'Bruce ', 'With t', 'World ', 'Use th', 'User m', 'When i',\n",
       "       'Why di', 'The da', 'Guards', 'Hacker', 'The ne', 'Constr',\n",
       "       'Death ', 'This s', 'Throug', 'Cellph', 'WP : T', 'WP Hom',\n",
       "       'Dragon', 'Dumble', 'Eight ', 'Emotio', 'Enormo', 'The sm',\n",
       "       'The st', 'The su', 'Using ', 'WP - A', 'Five m', 'Genius',\n",
       "       'The wa', 'They c', 'The ex', 'The go', 'The ma', 'Turns ',\n",
       "       '`` To ', '`` and', '90 min', 'A 1400', 'A Fing', '( OT )',\n",
       "       '( PI )', 'My fri', 'New Pl', '300 WP', '/r/Wri', '1 ( or',\n",
       "       '47 yea', '( NSFW', '( IP )', '( Harr', '( From', '( EU ?',\n",
       "       'Newly ', 'New Is', 'New Gu', 'NASA s', 'Mystic', '( TT )',\n",
       "       '( Name', 'A Dyin', 'A Chri', 'A Cali', '90 % o', '6 Quic',\n",
       "       \"6 '' o\", '`` THE', 'Two ad', 'Tumblr', 'Top ra', 'The le',\n",
       "       'The gu', 'The gr', 'The fo', 'This p', 'This i', 'They w',\n",
       "       'These ', 'Then ,', 'The vo', 'The vi', 'Got th', 'Google',\n",
       "       'Good o', 'God ha', 'Give A', 'Garbag', 'From l', 'For as',\n",
       "       'Food t', 'Focus ', 'Columb', 'Choose', 'End of', 'Empero',\n",
       "       'Edward', 'Eddie ', 'WP . M', 'To dec', 'To all', 'Three ',\n",
       "       'Threat', 'Dark s', 'Cthulh', 'Crimin', 'Cowboy', 'Finish',\n",
       "       'Everyt', 'Erotic', 'He was', 'He is ', 'Have y', 'Half a',\n",
       "       'Hair i', 'Guy is', 'The co', 'The ba', 'The av', 'Why ar',\n",
       "       'Who am', 'Tywin ', 'Two so', 'Two si', 'Two se', 'Two sc',\n",
       "       'We kno', 'We hav', 'We fou', \"We 're\", 'WP ] Y', 'X-post',\n",
       "       'With h', 'Cedar ', 'Caesar', 'Being ', 'Battle', 'Aug 16',\n",
       "       'At lon', 'The Su', 'The So', 'The Se', 'Talent', 'Take a',\n",
       "       'The Pr', 'The Ni', 'The Lo', 'The Hu', 'The Gu', 'The Em',\n",
       "       'You fo', 'You fe', 'You fa', 'What d', 'We liv', 'At bir',\n",
       "       'At a l', 'Ask Le', 'Any id', 'You ac', 'The Bo', 'How ha',\n",
       "       'Someth', 'I thou', 'I need', 'I ... ', \"I 'm d\", 'Your b',\n",
       "       'Your F', 'With a', 'Anti-a', 'Animal', 'And so', 'Ancien',\n",
       "       'An inv', 'An inf', 'An ero', \"The 'L\", \"She 's\", 'Sentie',\n",
       "       'In 200', 'Imager', 'If Wor', 'If God', 'Superm', 'Your t',\n",
       "       'Your s', 'Your r', 'Your p', 'You co', 'An ast', 'An Ato',\n",
       "       'An Arm', 'An Apo', 'An Ame', 'An Ali', 'Activi', '[ EU .',\n",
       "       '[ EU -', 'Your D', 'You we', 'You tr', 'You su', 'You st',\n",
       "       'You se', '[ CC ,', '[ Audi', 'Zarthu', 'A torn', 'A thro',\n",
       "       '[ IP/E', '[ Holi', 'Your l', 'Your h', 'Americ', 'Alter ',\n",
       "       'Almost', 'All yo', 'All pe', 'All cr', 'Alien ', 'Agents',\n",
       "       'A robb', 'A reti', 'A ramp', '[ Crit', '[ Cons', '[ CP ]',\n",
       "       'A-Z Mu', 'A wann', 'A very', 'A vaca', 'A typi', 'Sunday',\n",
       "       'Such a', 'Strand', 'Spellc', 'Rub Sa', 'Riley ', 'Reddit',\n",
       "       'Read t', 'Pregna', 'Interv', 'In you', 'In bet', 'In as ',\n",
       "       '[ PO ]', 'A race', '[ EUx3', '[ EU }', '[ EU ?', 'A team',\n",
       "       'A stat', 'A spee', 'A some', 'A sele', 'A scie', 'A larg',\n",
       "       'A kidn', 'A guy ', 'A good', 'A radi', '[ OT/M', '[ OFFT',\n",
       "       '[ Non-', '[ MP/I', '[ Time', '[ TT/E', '[ Stor', '[ RF ?',\n",
       "       '[ Poet', 'A desp', 'A day ', 'A cove', 'A psyc', 'A prev',\n",
       "       'A plan', 'A pain', 'A nucl', 'A news', 'A mill', 'A mega',\n",
       "       'A long', 'Show m', 'Member', 'Martyr', 'March ', 'Man/Wo',\n",
       "       'Make d', 'Major ', 'MORTEM', 'Look n', 'Lightp', 'Life i',\n",
       "       'A Vamp', '[ wP ]', 'A girl', '[ WP-C', '[ WP )', '[ WF ]',\n",
       "       'A firs', \"Life '\", 'Knowin', 'Johnny', 'One St', 'On Sep',\n",
       "       'On Mon', 'Octobe', 'Not en', 'Pirate', 'Our ca', '[ wr ]',\n",
       "       'A Swin', 'A Seri', 'A coup', '[ [ PM', '[ WPa ', 'A coll',\n",
       "       'A belo', 'A Warl', 'Much t', 'Morocc', '[ pi ]', '`` Hi ',\n",
       "       '`` Hey', '`` Fuc', '`` Eve', '`` Coc', '`` Aye', 'One of',\n",
       "       'Mild M', 'Michae', 'your b', 'writin', 'tell a', 'once b',\n",
       "       'her be', 'contin', 'a war ', '`` hey', '( W.P ', '( repo',\n",
       "       '( X-po', '`` My ', '\\ufeff [ PI', \"'It 's\", '`` I r', '`` I o'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(prefixes, return_counts=True)\n",
    "sorted_indices = np.argsort(-counts)\n",
    "unique, counts = unique[sorted_indices], counts[sorted_indices]\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.981180651243745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 14 prefiex account for 98% of the prefiexes\n",
    "sum(counts[:14]) / sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = unique[:14]\n",
    "pattern = r'^(?:' + '|'.join(re.escape(prefix) for prefix in prefixes) + r')\\s*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(text):\n",
    "    return re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You 've finally managed to discover the secret...</td>\n",
       "      <td>So many times have I walked on ruins, the rema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The moon is actually a giant egg , and it has ...</td>\n",
       "      <td>-Week 18 aboard the Depth Reaver, Circa 2023- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You find a rip in time walking through the all...</td>\n",
       "      <td>I was feckin' sloshed, mate. First time I ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For years in your youth the same imaginary cha...</td>\n",
       "      <td>“ No, no no no... ” She backed up and turned t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You glance at your watch 10:34 am , roughly 10...</td>\n",
       "      <td>There's a magical moment between wakefulness a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  You 've finally managed to discover the secret...   \n",
       "1  The moon is actually a giant egg , and it has ...   \n",
       "2  You find a rip in time walking through the all...   \n",
       "3  For years in your youth the same imaginary cha...   \n",
       "4  You glance at your watch 10:34 am , roughly 10...   \n",
       "\n",
       "                                               story  \n",
       "0  So many times have I walked on ruins, the rema...  \n",
       "1  -Week 18 aboard the Depth Reaver, Circa 2023- ...  \n",
       "2  I was feckin' sloshed, mate. First time I ever...  \n",
       "3  “ No, no no no... ” She backed up and turned t...  \n",
       "4  There's a magical moment between wakefulness a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"] = df[\"prompt\"].apply(remove_prefix)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prompt_length\"] = df[\"prompt\"].str.len()\n",
    "df[\"story_length\"] = df[\"story\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>story</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>story_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241209</th>\n",
       "      <td>- Rubidoux\\n</td>\n",
       "      <td>Cummings ambled downstairs. He shuffled throug...</td>\n",
       "      <td>11</td>\n",
       "      <td>9562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241029</th>\n",
       "      <td>Pilgrimage\\n</td>\n",
       "      <td>No words were spoken for the longest stretch o...</td>\n",
       "      <td>11</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241069</th>\n",
       "      <td>Brown Eyes\\n</td>\n",
       "      <td>You are sitting a bar in a small town by the H...</td>\n",
       "      <td>11</td>\n",
       "      <td>1847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240784</th>\n",
       "      <td>Meditation\\n</td>\n",
       "      <td>She'd stolen away in the wee hours of the morn...</td>\n",
       "      <td>11</td>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240742</th>\n",
       "      <td>Old Empire\\n</td>\n",
       "      <td>It was a bar, but not your idea of a bar. Ther...</td>\n",
       "      <td>11</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210138</th>\n",
       "      <td></td>\n",
       "      <td>I've lived in L.A for three years and never ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>3857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194490</th>\n",
       "      <td></td>\n",
       "      <td>I died. I'm sure of it. I saw all the color in...</td>\n",
       "      <td>0</td>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99246</th>\n",
       "      <td></td>\n",
       "      <td>I think AetherThought broke your essay down we...</td>\n",
       "      <td>0</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16469</th>\n",
       "      <td></td>\n",
       "      <td>And just like that it was done. \\n \\n \\n The d...</td>\n",
       "      <td>0</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87638</th>\n",
       "      <td></td>\n",
       "      <td>With a mighty heave the breech lock was thrown...</td>\n",
       "      <td>0</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              prompt                                              story  \\\n",
       "241209  - Rubidoux\\n  Cummings ambled downstairs. He shuffled throug...   \n",
       "241029  Pilgrimage\\n  No words were spoken for the longest stretch o...   \n",
       "241069  Brown Eyes\\n  You are sitting a bar in a small town by the H...   \n",
       "240784  Meditation\\n  She'd stolen away in the wee hours of the morn...   \n",
       "240742  Old Empire\\n  It was a bar, but not your idea of a bar. Ther...   \n",
       "...              ...                                                ...   \n",
       "210138                I've lived in L.A for three years and never ha...   \n",
       "194490                I died. I'm sure of it. I saw all the color in...   \n",
       "99246                 I think AetherThought broke your essay down we...   \n",
       "16469                 And just like that it was done. \\n \\n \\n The d...   \n",
       "87638                 With a mighty heave the breech lock was thrown...   \n",
       "\n",
       "        prompt_length  story_length  \n",
       "241209             11          9562  \n",
       "241029             11          1510  \n",
       "241069             11          1847  \n",
       "240784             11          1601  \n",
       "240742             11          1295  \n",
       "...               ...           ...  \n",
       "210138              0          3857  \n",
       "194490              0          2314  \n",
       "99246               0          1878  \n",
       "16469               0           904  \n",
       "87638               0           848  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"prompt_length\", ascending=False).tail(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(203)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=\"story\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(iterable, batch_size):\n",
    "    \"\"\"Splits an iterable into smaller batches.\"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    while batch := list(islice(iterable, batch_size)):\n",
    "        yield batch\n",
    "\n",
    "def save_to_csv(path, prompts, responses, temperature, top_p, top_k):\n",
    "    \"\"\"Saves prompts, responses and sampling parameters to a CSV file.\"\"\"\n",
    "    with open(path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for prompt, response in zip(prompts, responses):\n",
    "            writer.writerow([prompt, response, temperature, top_p, top_k])\n",
    "\n",
    "def generate_responses(model, prompts, sampling_params):\n",
    "    \"\"\"Generate a batch of outputs using vLLM with customizable sampling parameters.\"\"\"\n",
    "    outputs = model.chat(prompts, sampling_params=sampling_params, use_tqdm=False)\n",
    "    \n",
    "    return [sample.outputs[0].text.replace('\"', '') for sample in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = [{\"role\": \"system\", \"content\": \"You are a helpful assistant for writing stories based on provided prompt. Based on provided prompt generate a story. MAKE SURE TO REPLAY ONLY WITH THE STORY.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Prompt: \\n {prompt}\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Story: \\n\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    [\n",
    "        BASE_PROMPT[0],  # The system message\n",
    "        {\"role\": \"user\", \"content\": BASE_PROMPT[1][\"content\"].format(prompt=prompt)},  # Formatted user message\n",
    "        BASE_PROMPT[2]  # The assistant message\n",
    "    ]\n",
    "    for prompt in df[\"prompt\"].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2370it [01:01, 38.73it/s]                          \n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "batch_size = 128\n",
    "for prompts_batch in tqdm(batchify(prompts, batch_size), total=len(prompts) // batch_size):\n",
    "    tokens = tokenizer.apply_chat_template(prompts_batch)\n",
    "    lens.extend([len(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "too_large = [i for i, l in enumerate(lens) if l > 32_768]\n",
    "too_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"prompt\"], axis=1, inplace=True)\n",
    "df.to_csv(\"../../data/data_human/writingprompts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = [\n",
    "    SamplingParams(temperature=0.0, top_p=1.0, top_k=-1, max_tokens=30_000, seed=SEED),  # Pure Greedy (fully deterministic)\n",
    "    SamplingParams(temperature=0.2, top_p=1.0, top_k=-1, max_tokens=30_000, seed=SEED),  # Highly Deterministic\n",
    "    SamplingParams(temperature=0.5, top_p=0.95, top_k=100, max_tokens=30_000, seed=SEED), # Mildly Deterministic but Flexible\n",
    "    SamplingParams(temperature=0.7, top_p=0.9, top_k=50, max_tokens=30_000, seed=SEED),  # Balanced and Natural\n",
    "    SamplingParams(temperature=0.9, top_p=0.8, top_k=40, max_tokens=30_000, seed=SEED),  # Slightly More Diverse but Coherent\n",
    "    SamplingParams(temperature=1.0, top_p=0.95, top_k=30, max_tokens=30_000, seed=SEED), # Default Creative Mode\n",
    "    SamplingParams(temperature=1.2, top_p=0.7, top_k=20, max_tokens=30_000, seed=SEED),  # Highly Creative\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\"meta-llama/Llama-3.2-1B-Instruct\"]\n",
    "batch_size = 8\n",
    "base_path = \"../../data/data_ai/writingprompts/writingprompts_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-15 20:35:51 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-15 20:36:03 config.py:542] This model supports multiple tasks: {'generate', 'score', 'embed', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 02-15 20:36:03 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=10000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 02-15 20:36:06 interface.py:284] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 02-15 20:36:06 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 02-15 20:36:06 cuda.py:227] Using XFormers backend.\n",
      "INFO 02-15 20:36:07 model_runner.py:1110] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n",
      "INFO 02-15 20:36:08 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
      "INFO 02-15 20:36:08 weight_utils.py:297] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7134a86d46cc439e9ebe58fa2d6b9139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 20:36:52 model_runner.py:1115] Loading model weights took 2.3185 GB\n",
      "INFO 02-15 20:36:54 worker.py:267] Memory profiling takes 2.22 seconds\n",
      "INFO 02-15 20:36:54 worker.py:267] the current vLLM instance can use total_gpu_memory (6.00GiB) x gpu_memory_utilization (0.90) = 5.40GiB\n",
      "INFO 02-15 20:36:54 worker.py:267] model weights take 2.32GiB; non_torch_memory takes 0.04GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 1.84GiB.\n",
      "INFO 02-15 20:36:55 executor_base.py:110] # CUDA blocks: 3761, # CPU blocks: 8192\n",
      "INFO 02-15 20:36:55 executor_base.py:115] Maximum concurrency for 10000 tokens per request: 6.02x\n",
      "INFO 02-15 20:37:53 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:30<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 20:38:24 model_runner.py:1562] Graph capturing finished in 31 secs, took 0.12 GiB\n",
      "INFO 02-15 20:38:24 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 91.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/37919 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 20:38:24 chat_utils.py:332] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/37919 [00:40<215:40:30, 20.48s/it]\n"
     ]
    }
   ],
   "source": [
    "for llm in llms:\n",
    "    model = LLM(model=llm, dtype=\"half\", max_model_len = 10_000)\n",
    "    csv_path = f\"{base_path}{llm.split('/')[-1]}.csv\"\n",
    "\n",
    "\n",
    "    # init csv file\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"prompt\", \"response\", \"temperature\", \"top_p\", \"top_k\"])\n",
    "\n",
    "    cnt = 0\n",
    "    for prompts_batch in tqdm(batchify(prompts, batch_size), total=len(prompts) // batch_size):\n",
    "        params = random.choice(sampling_params)\n",
    "        responses = generate_responses(model, prompts_batch, params)\n",
    "        save_to_csv(csv_path, prompts_batch, responses, params.temperature, params.top_p, params.top_k)\n",
    "        cnt += 1\n",
    "        if cnt > 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "      <td>I stared at the business card in my hands, my ...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "      <td>**The Lunar Egg Awakens**\\n\\nDeep within the h...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "      <td>I slowly sat up, my mind reeling as I tried to...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "      <td>I had always been fascinated by the recurring ...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "      <td>I slowly opened my eyes, groggily taking in my...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [{'role': 'system', 'content': 'You are a help...   \n",
       "1  [{'role': 'system', 'content': 'You are a help...   \n",
       "2  [{'role': 'system', 'content': 'You are a help...   \n",
       "3  [{'role': 'system', 'content': 'You are a help...   \n",
       "4  [{'role': 'system', 'content': 'You are a help...   \n",
       "\n",
       "                                            response  temperature  top_p  \\\n",
       "0  I stared at the business card in my hands, my ...          1.2    0.7   \n",
       "1  **The Lunar Egg Awakens**\\n\\nDeep within the h...          1.2    0.7   \n",
       "2  I slowly sat up, my mind reeling as I tried to...          1.2    0.7   \n",
       "3  I had always been fascinated by the recurring ...          1.2    0.7   \n",
       "4  I slowly opened my eyes, groggily taking in my...          1.2    0.7   \n",
       "\n",
       "   top_k  \n",
       "0     20  \n",
       "1     20  \n",
       "2     20  \n",
       "3     20  \n",
       "4     20  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/data_ai/writingprompts/writingprompts_Llama-3.2-1B-Instruct.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
