{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-18 16:05:49 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1554/1128818070.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../../data/data_raw/essays.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sakibsh-llm-0</td>\n",
       "      <td>I just got back from your class, so I decided ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sakibsh-llm-1</td>\n",
       "      <td>It is 9:35 and I am beginning my stream of con...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sakibsh-llm-2</td>\n",
       "      <td>Not only was the server down but it has taken ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sakibsh-llm-3</td>\n",
       "      <td>I am not exactly sure how this is supposed to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sakibsh-llm-4</td>\n",
       "      <td>Well, here I am on Friday, September something...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        essay_id                                               text  label  \\\n",
       "0  sakibsh-llm-0  I just got back from your class, so I decided ...    0.0   \n",
       "1  sakibsh-llm-1  It is 9:35 and I am beginning my stream of con...    0.0   \n",
       "2  sakibsh-llm-2  Not only was the server down but it has taken ...    0.0   \n",
       "3  sakibsh-llm-3  I am not exactly sure how this is supposed to ...    0.0   \n",
       "4  sakibsh-llm-4  Well, here I am on Friday, September something...    0.0   \n",
       "\n",
       "                source prompt  \n",
       "0  sakibsh-llm-human-1    NaN  \n",
       "1  sakibsh-llm-human-1    NaN  \n",
       "2  sakibsh-llm-human-1    NaN  \n",
       "3  sakibsh-llm-human-1    NaN  \n",
       "4  sakibsh-llm-human-1    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/data_raw/essays.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id       0\n",
       "text           0\n",
       "label          0\n",
       "source         0\n",
       "prompt      2467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>sakibsh-llm-h2-47</td>\n",
       "      <td>I think obesity is bad but not that bad. If yo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Some states have now made it illegal to drive ...</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>sakibsh-llm-h2-155</td>\n",
       "      <td>I think 1st person narrator is a nice way to t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Discuss a piece of literature in which the aut...</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>sakibsh-llm-h2-32</td>\n",
       "      <td>In my opinion, should we install more surveill...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Many people feel that the use of surveillance ...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>sakibsh-llm-h2-65</td>\n",
       "      <td>My clas had to read Moby dick. I learned about...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Discuss the events in the life of your favorit...</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>sakibsh-llm-2370</td>\n",
       "      <td>I want to go to Mexico and dance I have not da...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>sakibsh-llm-h2-56</td>\n",
       "      <td>We have to take math. I donâ€™t like it. It is s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Math is a required subject. Explain why it is ...</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>sakibsh-llm-h2-29</td>\n",
       "      <td>Lot's of people are overwait and even fat, and...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Some people think that school cafeterias shoul...</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>sakibsh-llm-h2-74</td>\n",
       "      <td>Evryone shoold go to college because that educ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-2</td>\n",
       "      <td>Explain how to choose the right college.</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>sakibsh-llm-2257</td>\n",
       "      <td>this job is going to drain me if I don't say s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>sakibsh-llm-1740</td>\n",
       "      <td>alright. what can I talk about. well the only ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sakibsh-llm-human-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                essay_id                                               text  \\\n",
       "2514   sakibsh-llm-h2-47  I think obesity is bad but not that bad. If yo...   \n",
       "2622  sakibsh-llm-h2-155  I think 1st person narrator is a nice way to t...   \n",
       "2499   sakibsh-llm-h2-32  In my opinion, should we install more surveill...   \n",
       "2532   sakibsh-llm-h2-65  My clas had to read Moby dick. I learned about...   \n",
       "2370    sakibsh-llm-2370  I want to go to Mexico and dance I have not da...   \n",
       "2523   sakibsh-llm-h2-56  We have to take math. I donâ€™t like it. It is s...   \n",
       "2496   sakibsh-llm-h2-29  Lot's of people are overwait and even fat, and...   \n",
       "2541   sakibsh-llm-h2-74  Evryone shoold go to college because that educ...   \n",
       "2257    sakibsh-llm-2257  this job is going to drain me if I don't say s...   \n",
       "1740    sakibsh-llm-1740  alright. what can I talk about. well the only ...   \n",
       "\n",
       "      label               source  \\\n",
       "2514    0.0  sakibsh-llm-human-2   \n",
       "2622    0.0  sakibsh-llm-human-2   \n",
       "2499    0.0  sakibsh-llm-human-2   \n",
       "2532    0.0  sakibsh-llm-human-2   \n",
       "2370    0.0  sakibsh-llm-human-1   \n",
       "2523    0.0  sakibsh-llm-human-2   \n",
       "2496    0.0  sakibsh-llm-human-2   \n",
       "2541    0.0  sakibsh-llm-human-2   \n",
       "2257    0.0  sakibsh-llm-human-1   \n",
       "1740    0.0  sakibsh-llm-human-1   \n",
       "\n",
       "                                                 prompt  length  \n",
       "2514  Some states have now made it illegal to drive ...     327  \n",
       "2622  Discuss a piece of literature in which the aut...     325  \n",
       "2499  Many people feel that the use of surveillance ...     308  \n",
       "2532  Discuss the events in the life of your favorit...     306  \n",
       "2370                                                NaN     289  \n",
       "2523  Math is a required subject. Explain why it is ...     286  \n",
       "2496  Some people think that school cafeterias shoul...     272  \n",
       "2541           Explain how to choose the right college.     230  \n",
       "2257                                                NaN     217  \n",
       "1740                                                NaN     159  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"length\", ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"length\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=\"text\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(iterable, batch_size):\n",
    "    \"\"\"Splits an iterable into smaller batches.\"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    while batch := list(islice(iterable, batch_size)):\n",
    "        yield batch\n",
    "\n",
    "def save_to_csv(path, prompts, responses, temperature, top_p, top_k):\n",
    "    \"\"\"Saves prompts, responses and sampling parameters to a CSV file.\"\"\"\n",
    "    with open(path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for prompt, response in zip(prompts, responses):\n",
    "            writer.writerow([prompt, response, temperature, top_p, top_k])\n",
    "\n",
    "def generate_responses(model, prompts, sampling_params):\n",
    "    \"\"\"Generate a batch of outputs using vLLM with customizable sampling parameters.\"\"\"\n",
    "    outputs = model.chat(prompts, sampling_params=sampling_params, use_tqdm=False)\n",
    "    \n",
    "    return [sample.outputs[0].text.replace('\"', '') for sample in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = [{\"role\": \"system\", \"content\": \"You are a helpful asistant for rewritting students' essays. Based on provided essay generate a similar one. MAKE SURE TO REPLAY ONLY WITH THE SIMILAR ESSAY.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Essay: \\n {essay}\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Similar essay: \\n\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    [\n",
    "        BASE_PROMPT[0],  # The system message\n",
    "        {\"role\": \"user\", \"content\": BASE_PROMPT[1][\"content\"].format(essay=essay)},  # Formatted user message\n",
    "        BASE_PROMPT[2]  # The assistant message\n",
    "    ]\n",
    "    for essay in df[\"text\"].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:04,  4.63it/s]                        \n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "batch_size = 128\n",
    "for prompts_batch in tqdm(batchify(prompts, batch_size), total=len(prompts) // batch_size):\n",
    "    tokens = tokenizer.apply_chat_template(prompts_batch)\n",
    "    lens.extend([len(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "too_large = [i for i, l in enumerate(lens) if l > 32_768]\n",
    "too_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"essay_id\", \"label\", \"source\", \"prompt\"], axis=1, inplace=True)\n",
    "df.to_csv(\"../../data/data_human/essays.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = [\n",
    "    SamplingParams(temperature=0.0, top_p=1.0, top_k=-1, max_tokens=30_000, seed=SEED),  # Pure Greedy (fully deterministic)\n",
    "    SamplingParams(temperature=0.2, top_p=1.0, top_k=-1, max_tokens=30_000, seed=SEED),  # Highly Deterministic\n",
    "    SamplingParams(temperature=0.5, top_p=0.95, top_k=100, max_tokens=30_000, seed=SEED), # Mildly Deterministic but Flexible\n",
    "    SamplingParams(temperature=0.7, top_p=0.9, top_k=50, max_tokens=30_000, seed=SEED),  # Balanced and Natural\n",
    "    SamplingParams(temperature=0.9, top_p=0.8, top_k=40, max_tokens=30_000, seed=SEED),  # Slightly More Diverse but Coherent\n",
    "    SamplingParams(temperature=1.0, top_p=0.95, top_k=30, max_tokens=30_000, seed=SEED), # Default Creative Mode\n",
    "    SamplingParams(temperature=1.2, top_p=0.7, top_k=20, max_tokens=30_000, seed=SEED),  # Highly Creative\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\"meta-llama/Llama-3.2-1B-Instruct\"]\n",
    "batch_size = 8\n",
    "base_path = \"../../data/data_ai/essays/essays_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-15 06:37:40 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-15 06:37:55 config.py:542] This model supports multiple tasks: {'classify', 'embed', 'generate', 'reward', 'score'}. Defaulting to 'generate'.\n",
      "INFO 02-15 06:37:55 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=10000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 02-15 06:37:58 interface.py:284] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 02-15 06:37:59 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 02-15 06:37:59 cuda.py:227] Using XFormers backend.\n",
      "INFO 02-15 06:38:00 model_runner.py:1110] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n",
      "INFO 02-15 06:38:01 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
      "INFO 02-15 06:38:02 weight_utils.py:297] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb03906fa91c462f8cb64c3c7bc7357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 06:38:09 model_runner.py:1115] Loading model weights took 2.3185 GB\n",
      "INFO 02-15 06:38:12 worker.py:267] Memory profiling takes 2.84 seconds\n",
      "INFO 02-15 06:38:12 worker.py:267] the current vLLM instance can use total_gpu_memory (6.00GiB) x gpu_memory_utilization (0.90) = 5.40GiB\n",
      "INFO 02-15 06:38:12 worker.py:267] model weights take 2.32GiB; non_torch_memory takes 0.04GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 1.84GiB.\n",
      "INFO 02-15 06:38:13 executor_base.py:110] # CUDA blocks: 3761, # CPU blocks: 8192\n",
      "INFO 02-15 06:38:13 executor_base.py:115] Maximum concurrency for 10000 tokens per request: 6.02x\n",
      "INFO 02-15 06:38:23 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:31<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 06:38:55 model_runner.py:1562] Graph capturing finished in 32 secs, took 0.12 GiB\n",
      "INFO 02-15 06:38:55 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 45.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-15 06:38:55 chat_utils.py:332] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/329 [02:48<7:38:34, 84.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for llm in llms:\n",
    "    model = LLM(model=llm, dtype=\"half\", max_model_len = 10_000)\n",
    "    csv_path = f\"{base_path}{llm.split('/')[-1]}.csv\"\n",
    "\n",
    "\n",
    "    # init csv file\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"prompt\", \"response\", \"temperature\", \"top_p\", \"top_k\"])\n",
    "\n",
    "    cnt = 0\n",
    "    for prompts_batch in tqdm(batchify(prompts, batch_size), total=len(prompts) // batch_size):\n",
    "        params = random.choice(sampling_params)\n",
    "        responses = generate_responses(model, prompts_batch, params)\n",
    "        save_to_csv(csv_path, prompts_batch, responses, params.temperature, params.top_p, params.top_k)\n",
    "        cnt += 1\n",
    "        if cnt > 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'system', 'content': \"You are a help...</td>\n",
       "      <td>I recently attended my first class, and I'm ex...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'system', 'content': \"You are a help...</td>\n",
       "      <td>It's 9:35 and I'm starting my stream of consci...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'role': 'system', 'content': \"You are a help...</td>\n",
       "      <td>As I sat in front of my computer, the server s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'role': 'system', 'content': \"You are a help...</td>\n",
       "      <td>I'm happy to help you with rewriting your essa...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'role': 'system', 'content': \"You are a help...</td>\n",
       "      <td>I'm writing this essay on Friday, September 15...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [{'role': 'system', 'content': \"You are a help...   \n",
       "1  [{'role': 'system', 'content': \"You are a help...   \n",
       "2  [{'role': 'system', 'content': \"You are a help...   \n",
       "3  [{'role': 'system', 'content': \"You are a help...   \n",
       "4  [{'role': 'system', 'content': \"You are a help...   \n",
       "\n",
       "                                            response  temperature  top_p  \\\n",
       "0  I recently attended my first class, and I'm ex...          1.2    0.7   \n",
       "1  It's 9:35 and I'm starting my stream of consci...          1.2    0.7   \n",
       "2  As I sat in front of my computer, the server s...          1.2    0.7   \n",
       "3  I'm happy to help you with rewriting your essa...          1.2    0.7   \n",
       "4  I'm writing this essay on Friday, September 15...          1.2    0.7   \n",
       "\n",
       "   top_k  \n",
       "0     20  \n",
       "1     20  \n",
       "2     20  \n",
       "3     20  \n",
       "4     20  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/data_ai/essays/essays_Llama-3.2-1B-Instruct.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
