{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/data_raw/tweets.csv\", encoding='latin-1', names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"target\", \"ids\", \"date\", \"flag\", \"user\"], axis=1, inplace=True)\n",
    "df.to_csv(\"../../data/data_human/tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-11 04:26:46 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-11 04:26:50 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 02-11 04:27:04 config.py:542] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.\n",
      "INFO 02-11 04:27:04 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=10000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 02-11 04:27:07 interface.py:284] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 02-11 04:27:07 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 02-11 04:27:07 cuda.py:227] Using XFormers backend.\n",
      "INFO 02-11 04:27:08 model_runner.py:1110] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n",
      "INFO 02-11 04:27:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
      "INFO 02-11 04:27:09 weight_utils.py:297] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f8b18961ac4041ae63653f1c54315c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-11 04:27:49 model_runner.py:1115] Loading model weights took 2.3185 GB\n",
      "INFO 02-11 04:27:51 worker.py:267] Memory profiling takes 1.84 seconds\n",
      "INFO 02-11 04:27:51 worker.py:267] the current vLLM instance can use total_gpu_memory (6.00GiB) x gpu_memory_utilization (0.90) = 5.40GiB\n",
      "INFO 02-11 04:27:51 worker.py:267] model weights take 2.32GiB; non_torch_memory takes 0.04GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 1.84GiB.\n",
      "INFO 02-11 04:27:52 executor_base.py:110] # CUDA blocks: 3761, # CPU blocks: 8192\n",
      "INFO 02-11 04:27:52 executor_base.py:115] Maximum concurrency for 10000 tokens per request: 6.02x\n",
      "INFO 02-11 04:27:57 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:21<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-11 04:28:19 model_runner.py:1562] Graph capturing finished in 19 secs, took 0.12 GiB\n",
      "INFO 02-11 04:28:19 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 29.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"meta-llama/Llama-3.2-1B-Instruct\", dtype=\"half\", max_model_len = 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Write a short story about a space explorer.\",\n",
    "    \"Explain the concept of quantum entanglement in simple terms.\",\n",
    "    \"Generate a creative recipe using chocolate and strawberries.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts *= 2000\n",
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   2%|▏         | 2564/120000 [04:23<3:09:03, 10.35it/s, est. speed input: 110.38 toks/s, output: 155.82 toks/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/utils.py:1086\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1081\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1082\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1083\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m         )\n\u001b[0;32m-> 1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/entrypoints/llm.py:469\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[0m\n\u001b[1;32m    459\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_sampling_params()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    462\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mparsed_prompts,\n\u001b[1;32m    463\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request,\n\u001b[1;32m    467\u001b[0m     priority\u001b[38;5;241m=\u001b[39mpriority)\n\u001b[0;32m--> 469\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/entrypoints/llm.py:1390\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m   1388\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m-> 1390\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m   1392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/engine/llm_engine.py:1386\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_async_output_proc:\n\u001b[1;32m   1383\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1384\u001b[0m         virtual_engine]\n\u001b[0;32m-> 1386\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;66;03m# We need to do this here so that last step's sampled_token_ids can\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;66;03m# be passed to the next iteration for PP.\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_config\u001b[38;5;241m.\u001b[39mis_multi_step:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/executor/executor_base.py:138\u001b[0m, in \u001b[0;36mExecutorBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 138\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py:51\u001b[0m, in \u001b[0;36mUniProcExecutor.collective_rpc\u001b[0;34m(self, method, timeout, args, kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 51\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/utils.py:2220\u001b[0m, in \u001b[0;36mrun_method\u001b[0;34m(obj, method, args, kwargs)\u001b[0m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2219\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/worker/worker_base.py:413\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    409\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    410\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 413\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/worker/model_runner.py:1775\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps)\u001b[0m\n\u001b[1;32m   1772\u001b[0m     model_input\u001b[38;5;241m.\u001b[39masync_callback()\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m-> 1775\u001b[0m output: SamplerOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time\n\u001b[1;32m   1781\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1782\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/model_executor/models/llama.py:557\u001b[0m, in \u001b[0;36mLlamaForCausalLM.sample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    556\u001b[0m            sampling_metadata: SamplingMetadata) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 557\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:288\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    285\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m maybe_deferred_sample_results, maybe_sampled_tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_gpu_probs_tensor:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:853\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\n\u001b[1;32m    834\u001b[0m     probs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    835\u001b[0m     logprobs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    839\u001b[0m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    840\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleReturnType:\n\u001b[1;32m    841\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;124;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:822\u001b[0m, in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    810\u001b[0m maybe_deferred_args \u001b[38;5;241m=\u001b[39m SampleResultArgsType(\n\u001b[1;32m    811\u001b[0m     sampling_metadata\u001b[38;5;241m=\u001b[39msampling_metadata,\n\u001b[1;32m    812\u001b[0m     sample_metadata\u001b[38;5;241m=\u001b[39msample_metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m     beam_search_logprobs\u001b[38;5;241m=\u001b[39mbeam_search_logprobs,\n\u001b[1;32m    816\u001b[0m     sample_results_dict\u001b[38;5;241m=\u001b[39msample_results_dict)\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata\u001b[38;5;241m.\u001b[39mskip_sampler_cpu_output:\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    828\u001b[0m         maybe_deferred_args,\n\u001b[1;32m    829\u001b[0m         sampled_token_ids_tensor,\n\u001b[1;32m    830\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:687\u001b[0m, in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    685\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType\u001b[38;5;241m.\u001b[39mRANDOM, SamplingType\u001b[38;5;241m.\u001b[39mRANDOM_SEED):\n\u001b[0;32m--> 687\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m SamplingType\u001b[38;5;241m.\u001b[39mBEAM:\n\u001b[1;32m    690\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _beam_search_sample(seq_groups,\n\u001b[1;32m    691\u001b[0m                                          beam_search_logprobs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py:486\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, random_samples)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run random sampling on a given samples.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# Find the maximum n value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    488\u001b[0m results: SampleResultType \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=0, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Orion Blackwood led his crew, the Starsong, on a perilous', token_ids=(22022, 69773, 5348, 6798, 6197, 813, 13941, 11, 279, 25676, 647, 11, 389, 264, 60392, 788), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.3704019, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.05137062072753906, finished_time=1739235409.2183104, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=1, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine you have two toy cars that are connected in such a way that when one', token_ids=(38891, 499, 617, 1403, 22068, 9515, 430, 527, 8599, 304, 1778, 264, 1648, 430, 994, 832), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.3988323, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.02294015884399414, finished_time=1739235409.2184732, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=2, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Tiramisu can be replaced with a similar dessert.\\n\\n**Introducing... Chocolate', token_ids=(350, 67808, 63848, 649, 387, 12860, 449, 264, 4528, 43849, 382, 334, 1090, 60637, 1131, 39520), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.404762, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.01701045036315918, finished_time=1739235409.2184904, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=3, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson stood at the edge of the control room, his eyes fixed on', token_ids=(22022, 7957, 263, 14980, 520, 279, 6964, 315, 279, 2585, 3130, 11, 813, 6548, 8521, 389), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4061484, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.015624046325683594, finished_time=1739235409.2185001, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=4, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Here's a step-by-step guide on how it works:\\n\\n**Quantum Ent\", token_ids=(5810, 596, 264, 3094, 14656, 30308, 8641, 389, 1268, 433, 4375, 1473, 334, 45320, 372, 4968), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4063647, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.015407800674438477, finished_time=1739235409.218509, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=5, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' The recipe should be similar to a simple tune or song with a clever, word', token_ids=(578, 11363, 1288, 387, 4528, 311, 264, 4382, 26306, 477, 5609, 449, 264, 28799, 11, 3492), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4065409, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.015231609344482422, finished_time=1739235409.218517, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=6, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Orion Blackwood gazed out at the stars, his eyes burning with an', token_ids=(22022, 69773, 5348, 6798, 342, 28109, 704, 520, 279, 9958, 11, 813, 6548, 20252, 449, 459), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4067738, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.014998674392700195, finished_time=1739235409.2185237, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=7, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine two rabbits living together in a cozy burrow, each playing with a ball', token_ids=(38891, 1403, 70244, 5496, 3871, 304, 264, 43535, 7951, 654, 11, 1855, 5737, 449, 264, 5041), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4069383, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.014834165573120117, finished_time=1739235409.2185295, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=8, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Strawberry-Balsamic Chocolate Mousse Tarts\\n\\nIngredients:\\n- 8-', token_ids=(89077, 7826, 1147, 4079, 39520, 386, 46651, 350, 7183, 271, 46847, 512, 12, 220, 23, 12), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4070876, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.014684915542602539, finished_time=1739235409.2185364, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=9, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain James \"Hawk\" Hawkins, a seasoned space traveler, cruised through', token_ids=(22022, 7957, 330, 39, 24286, 1, 70687, 11, 264, 52614, 3634, 63865, 11, 23010, 4147, 1555), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4072313, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.014541149139404297, finished_time=1739235409.2185428, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=10, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Think like a freshman in physics.\\nImagine two balls are connected by an invisible string', token_ids=(21834, 1093, 264, 41317, 304, 22027, 627, 52157, 1403, 20953, 527, 8599, 555, 459, 30547, 925), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4073908, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.014381647109985352, finished_time=1739235409.2185493, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=11, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Strawberry Peach Chocolate Crumble.\\n\\nStart by preparing the frangipane filling,', token_ids=(89077, 64695, 39520, 4656, 23568, 382, 3563, 555, 20646, 279, 1448, 526, 575, 2194, 21973, 11), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4075427, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.014229774475097656, finished_time=1739235409.218556, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=12, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson stood on the edge of the spacecraft, gazing out at the', token_ids=(22022, 7957, 263, 14980, 389, 279, 6964, 315, 279, 42640, 11, 342, 6795, 704, 520, 279), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4080598, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.013712644577026367, finished_time=1739235409.2186015, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=13, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Imagine you're holding two connected apples.\\n\\nOnce the entangled states are created,\", token_ids=(38891, 499, 2351, 10168, 1403, 8599, 41776, 382, 12805, 279, 1218, 40040, 5415, 527, 3549, 11), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4084222, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.013350248336791992, finished_time=1739235409.218615, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=14, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' \"Berry Chocolate Bliss\" dessert that is perfect for a romantic evening or a special', token_ids=(330, 51302, 39520, 92670, 1, 43849, 430, 374, 4832, 369, 264, 24364, 11714, 477, 264, 3361), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4086902, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.013082265853881836, finished_time=1739235409.2186232, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=15, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson gazed out at the vast expanse of stars, feeling a', token_ids=(22022, 7957, 263, 342, 28109, 704, 520, 279, 13057, 506, 95519, 315, 9958, 11, 8430, 264), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4089446, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.012827873229980469, finished_time=1739235409.2186298, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=16, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine you have two toy boxes labeled as \"Me\" and \"You\".\\n\\nImagine', token_ids=(38891, 499, 617, 1403, 22068, 15039, 30929, 439, 330, 7979, 1, 323, 330, 2675, 11690, 52157), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.409224, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.012548446655273438, finished_time=1739235409.2186368, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=17, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Chocolate Mousse is an exciting recipe, right here!\\nTitle: The Whims', token_ids=(39520, 386, 46651, 374, 459, 13548, 11363, 11, 1314, 1618, 4999, 3936, 25, 578, 1254, 5861), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4094524, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.01232004165649414, finished_time=1739235409.2186434, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=18, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson gazed out at the stars, his mind whirling with memories', token_ids=(22022, 7957, 263, 342, 28109, 704, 520, 279, 9958, 11, 813, 4059, 421, 51868, 449, 19459), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4096208, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.012151718139648438, finished_time=1739235409.2186496, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=19, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Let's focus on the 'quantum' part.\\n\\nQuantum entanglement\", token_ids=(6914, 596, 5357, 389, 279, 364, 31548, 372, 6, 961, 382, 45320, 372, 1218, 526, 1001), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4097674, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.012005090713500977, finished_time=1739235409.2186596, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=20, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' who can resist the sweetness of these two?\\n\\nHere are some easy recipes I found', token_ids=(889, 649, 22884, 279, 64550, 315, 1521, 1403, 1980, 8586, 527, 1063, 4228, 19141, 358, 1766), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.410372, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.011400461196899414, finished_time=1739235409.2186663, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=21, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson Hale stood at the edge of the void, the vast expanse', token_ids=(22022, 7957, 263, 67251, 14980, 520, 279, 6964, 315, 279, 742, 11, 279, 13057, 506, 95519), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.410717, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.011055469512939453, finished_time=1739235409.2186723, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=22, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' You can delve into the physics and mathematics behind the concept, or provide some analog', token_ids=(1472, 649, 82845, 1139, 279, 22027, 323, 38696, 4920, 279, 7434, 11, 477, 3493, 1063, 24291), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4108992, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.01087331771850586, finished_time=1739235409.2186801, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=23, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Who says chocolate and strawberries have to be just for sweet treats?\\n\\nIntroducing the', token_ids=(10699, 2795, 18414, 323, 76203, 617, 311, 387, 1120, 369, 10437, 32839, 1980, 1090, 60637, 279), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4110773, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.010695219039916992, finished_time=1739235409.2186868, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=24, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Ortega and her trusty spaceship, the Aurora, blasted off into the', token_ids=(22022, 2582, 93005, 323, 1077, 7095, 88, 85942, 11, 279, 47892, 11, 63421, 1022, 1139, 279), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4112515, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.01052093505859375, finished_time=1739235409.2186928, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=25, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" I'll leave it there for now. Please provide a concise version.\\n\\n## Step\", token_ids=(358, 3358, 5387, 433, 1070, 369, 1457, 13, 5321, 3493, 264, 64694, 2373, 382, 567, 15166), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4114022, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.010370254516601562, finished_time=1739235409.2186992, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=26, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Strawberry Horseradish Sauce!\\n\\nIngredients:\\n\\n* 2 cups of sliced strawberries', token_ids=(89077, 15083, 805, 329, 819, 61276, 2268, 46847, 1473, 9, 220, 17, 26446, 315, 48715, 76203), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4115577, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.010214805603027344, finished_time=1739235409.2187066, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=27, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" astronaut Jack Harris was leading a mission to Jupiter's moon Io in the year \", token_ids=(47733, 7762, 21750, 574, 6522, 264, 9131, 311, 50789, 596, 18266, 30755, 304, 279, 1060, 220), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4117146, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.010057926177978516, finished_time=1739235409.218753, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=28, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine two dice, each with a number from 1 to 6.\\nThe', token_ids=(38891, 1403, 22901, 11, 1855, 449, 264, 1396, 505, 220, 16, 311, 220, 21, 627, 791), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4118605, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.00991201400756836, finished_time=1739235409.2187684, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=29, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Chocolate and strawberry are not just for breakfast, but can be combined in many sweet', token_ids=(39520, 323, 73700, 527, 539, 1120, 369, 17954, 11, 719, 649, 387, 11093, 304, 1690, 10437), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4120262, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.009746313095092773, finished_time=1739235409.2187757, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=30, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson piloted his trusty spaceship, the \"Aurora\",', token_ids=(22022, 7957, 263, 11715, 9437, 813, 7095, 88, 85942, 11, 279, 330, 32, 324, 6347, 498), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4121754, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.009597063064575195, finished_time=1739235409.218782, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=31, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine two particles that are connected, no matter where they are.\\n\\n## Step ', token_ids=(38891, 1403, 19252, 430, 527, 8599, 11, 912, 5030, 1405, 814, 527, 382, 567, 15166, 220), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4123192, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.009453296661376953, finished_time=1739235409.2187881, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=32, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Chocolate and strawberries are a classic combination, but with a twist, let's introduce\", token_ids=(39520, 323, 76203, 527, 264, 11670, 10824, 11, 719, 449, 264, 27744, 11, 1095, 596, 19678), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4124825, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.009289979934692383, finished_time=1739235409.2187934, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=33, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson \"Hawk\" Hawkins was the leader of the crew of the', token_ids=(22022, 7957, 263, 330, 39, 24286, 1, 70687, 574, 279, 7808, 315, 279, 13941, 315, 279), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4126408, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.009131669998168945, finished_time=1739235409.2188585, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=34, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Imagine you're on a train and a friend is sitting in a car far away\", token_ids=(38891, 499, 2351, 389, 264, 5542, 323, 264, 4333, 374, 11961, 304, 264, 1841, 3117, 3201), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4128058, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.008966684341430664, finished_time=1739235409.2188742, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=35, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Dark chocolate peanut butter cups are a classic dessert favorite, but combining them with strawberries', token_ids=(12538, 18414, 50933, 14432, 26446, 527, 264, 11670, 43849, 7075, 11, 719, 35271, 1124, 449, 76203), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.412956, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.00881648063659668, finished_time=1739235409.2194617, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=36, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jack \"Hawk\" Hawkins, a seasoned space traveler with the United Galactic', token_ids=(22022, 7762, 330, 39, 24286, 1, 70687, 11, 264, 52614, 3634, 63865, 449, 279, 3723, 76317), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4131196, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.008652925491333008, finished_time=1739235409.2195144, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=37, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Imagine you're in a room with two other people, and you throw a ball\", token_ids=(38891, 499, 2351, 304, 264, 3130, 449, 1403, 1023, 1274, 11, 323, 499, 2571, 264, 5041), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4133594, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.008413076400756836, finished_time=1739235409.219528, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=38, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Strawberry and Chocolate Mousse can be made using chocolate cake or brownies and strawberry', token_ids=(89077, 323, 39520, 386, 46651, 649, 387, 1903, 1701, 18414, 19692, 477, 14198, 552, 323, 73700), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4135356, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.008236885070800781, finished_time=1739235409.219538, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=39, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson \"Hawk\" Hawkins, a veteran of many planetary excursions', token_ids=(22022, 7957, 263, 330, 39, 24286, 1, 70687, 11, 264, 21487, 315, 1690, 62938, 3521, 76339), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.41369, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.008082389831542969, finished_time=1739235409.2195466, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=40, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' The following problem also attempts to apply quantum principles to some real-world applications.\\n\\nConsider', token_ids=(578, 2768, 3575, 1101, 13865, 311, 3881, 31228, 16565, 311, 1063, 1972, 31184, 8522, 382, 38275), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.413851, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.007921457290649414, finished_time=1739235409.2195551, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=41, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Strawberry-Balsamic Glazed Salmon with Chocolate-Dipped Strawberry Skewers is', token_ids=(89077, 7826, 1147, 4079, 8444, 28109, 62826, 449, 39520, 9607, 6586, 89077, 4923, 365, 388, 374), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4140816, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.007690906524658203, finished_time=1739235409.2195644, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=42, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Captain's orders were to scout out the unexplored sector of space on the\", token_ids=(22022, 596, 10373, 1051, 311, 54594, 704, 279, 653, 69331, 1171, 10706, 315, 3634, 389, 279), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.414293, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.007479429244995117, finished_time=1739235409.2196965, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=43, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine you have two dancers.\\n\\nImagine that you have two dancers, you and your', token_ids=(38891, 499, 617, 1403, 61583, 382, 52157, 430, 499, 617, 1403, 61583, 11, 499, 323, 701), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4144592, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.007313251495361328, finished_time=1739235409.2197173, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=44, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Chocolate Strawberry Tart with Whipped Cream and Balsamic Glaze\\n\\nIngredients:\\n\\n', token_ids=(39520, 89077, 78641, 449, 1254, 6586, 30800, 323, 426, 1147, 4079, 8444, 10033, 271, 46847, 1473), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4146101, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.007162332534790039, finished_time=1739235409.2197719, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=45, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Orion Blackwood.\\n\\n**The Darkness of New Jupiter**\\n\\nCaptain Orion Blackwood', token_ids=(22022, 69773, 5348, 6798, 382, 334, 791, 54796, 315, 1561, 50789, 57277, 62158, 69773, 5348, 6798), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4147525, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.007019996643066406, finished_time=1739235409.219789, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=46, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Imagine you're sitting across from your partner in a restaurant, holding hands. You\", token_ids=(38891, 499, 2351, 11961, 4028, 505, 701, 8427, 304, 264, 10960, 11, 10168, 6206, 13, 1472), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4149911, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.006781339645385742, finished_time=1739235409.2197988, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=47, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Create a visually appealing dish with vibrant colors and lush ingredients. Here's a recipe\", token_ids=(4324, 264, 43395, 33352, 12269, 449, 34076, 8146, 323, 58367, 14293, 13, 5810, 596, 264, 11363), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4152093, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.0065631866455078125, finished_time=1739235409.2198088, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=48, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Orion Blackwood piloted the sleek, silver ship, the \"Aur', token_ids=(22022, 69773, 5348, 6798, 11715, 9437, 279, 48494, 11, 15310, 8448, 11, 279, 330, 32, 324), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4155624, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.0062100887298583984, finished_time=1739235409.2198176, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=49, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine you have two toy cars that are connected in such a way that they can', token_ids=(38891, 499, 617, 1403, 22068, 9515, 430, 527, 8599, 304, 1778, 264, 1648, 430, 814, 649), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4158525, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.005919933319091797, finished_time=1739235409.2198262, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=50, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Strawberry-Balsamic Tart with Chocolate Ganache.\\nLet your taste buds indulge in', token_ids=(89077, 7826, 1147, 4079, 78641, 449, 39520, 50181, 1815, 627, 10267, 701, 12945, 68543, 68190, 304), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4160712, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.005701303482055664, finished_time=1739235409.2198832, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=51, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Sarah Jenkins, a seasoned astronaut, piloted the state-of-the-art spaceship', token_ids=(22022, 21077, 45236, 11, 264, 52614, 47733, 11, 11715, 9437, 279, 1614, 8838, 10826, 38921, 85942), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4162745, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.005497932434082031, finished_time=1739235409.219903, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=52, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" Imagine two light bulbs.\\n\\nLet's use these two bulbs as an example. Imagine\", token_ids=(38891, 1403, 3177, 54320, 382, 10267, 596, 1005, 1521, 1403, 54320, 439, 459, 3187, 13, 38891), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.416433, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.005339384078979492, finished_time=1739235409.219913, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=53, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' This recipe combines the richness of dark chocolate with the sweetness of fresh strawberries.\\n\\n###', token_ids=(1115, 11363, 33511, 279, 90030, 315, 6453, 18414, 449, 279, 64550, 315, 7878, 76203, 382, 14711), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4165866, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.005185842514038086, finished_time=1739235409.2199225, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=54, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' A young and ambitious astronaut named Emma, had a strange and ominous dream about a', token_ids=(362, 3995, 323, 32855, 47733, 7086, 36035, 11, 1047, 264, 15234, 323, 86596, 8063, 922, 264), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4167418, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.005030632019042969, finished_time=1739235409.2199318, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=55, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Imagine you have two players in a game of Exploding Kittens. They are', token_ids=(38891, 499, 617, 1403, 4311, 304, 264, 1847, 315, 18491, 3785, 81767, 729, 13, 2435, 527), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4169116, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.004860877990722656, finished_time=1739235409.2199411, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=56, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' \\n\\n**Strawberry Chocolate Tartlets**\\n\\n**Servings:** 12-', token_ids=(4815, 334, 2645, 675, 15717, 39520, 78641, 10145, 57277, 334, 40259, 826, 68063, 220, 717, 12), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4170814, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.004691123962402344, finished_time=1739235409.2199492, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=57, prompt='Write a short story about a space explorer.', prompt_token_ids=[128000, 8144, 264, 2875, 3446, 922, 264, 3634, 54067, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Captain Jameson \"Hawk\" Hawkins, a seasoned astronaut, had been traveling', token_ids=(22022, 7957, 263, 330, 39, 24286, 1, 70687, 11, 264, 52614, 47733, 11, 1047, 1027, 21646), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.417229, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.0045435428619384766, finished_time=1739235409.2200077, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=58, prompt='Explain the concept of quantum entanglement in simple terms.', prompt_token_ids=[128000, 849, 21435, 279, 7434, 315, 31228, 1218, 526, 1001, 304, 4382, 3878, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' In your answer, include some visual aids and analogies to help explain the concept', token_ids=(763, 701, 4320, 11, 2997, 1063, 9302, 52797, 323, 24291, 552, 311, 1520, 10552, 279, 7434), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.417414, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.004358530044555664, finished_time=1739235409.220025, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={}),\n",
       " RequestOutput(request_id=59, prompt='Generate a creative recipe using chocolate and strawberries.', prompt_token_ids=[128000, 32215, 264, 11782, 11363, 1701, 18414, 323, 76203, 13], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Chocolate-Dipped Strawberry Tartlets.\\n\\n**Chocolate-Dipped Strawberry Tartlets**\\n\\nIngredients', token_ids=(39520, 9607, 6586, 89077, 78641, 10145, 382, 334, 94064, 9607, 6586, 89077, 78641, 10145, 57277, 46847), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1739235408.4175904, last_token_time=1739235409.2165337, first_scheduled_time=1739235408.4217725, first_token_time=1739235408.619185, time_in_queue=0.004182100296020508, finished_time=1739235409.2200348, scheduler_time=0.01740836900034992, model_forward_time=None, model_execute_time=None), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [sample.outputs[0].text for sample in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it, est. speed input: 9.97 toks/s, output: 124.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it, est. speed input: 9.83 toks/s, output: 147.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it, est. speed input: 11.81 toks/s, output: 147.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it, est. speed input: 11.85 toks/s, output: 148.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it, est. speed input: 9.87 toks/s, output: 148.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it, est. speed input: 11.74 toks/s, output: 146.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it, est. speed input: 11.75 toks/s, output: 146.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it, est. speed input: 9.94 toks/s, output: 149.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it, est. speed input: 10.83 toks/s, output: 135.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it, est. speed input: 9.31 toks/s, output: 116.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:06<00:00,  3.41s/it, est. speed input: 2.93 toks/s, output: 43.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it, est. speed input: 8.48 toks/s, output: 105.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it, est. speed input: 11.59 toks/s, output: 144.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it, est. speed input: 9.17 toks/s, output: 137.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it, est. speed input: 11.31 toks/s, output: 141.34 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to responses.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import islice\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def batchify(iterable, batch_size):\n",
    "    \"\"\"Splits an iterable into smaller batches.\"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    while batch := list(islice(iterable, batch_size)):\n",
    "        yield batch\n",
    "\n",
    "def save_to_csv(filename, prompts, responses):\n",
    "    \"\"\"Saves prompts and responses to a CSV file.\"\"\"\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for prompt, response in zip(prompts, responses):\n",
    "            writer.writerow([prompt, response])\n",
    "\n",
    "def generate_responses(prompts, temperature=0.8, top_p=0.95, max_tokens=100):\n",
    "    \"\"\"\n",
    "    Generate a batch of outputs using vLLM with customizable sampling parameters.\n",
    "\n",
    "    Args:\n",
    "        prompts (list of str): List of input prompts.\n",
    "        temperature (float): Sampling temperature.\n",
    "        top_p (float): Nucleus sampling parameter.\n",
    "        max_tokens (int): Maximum number of tokens in the output.\n",
    "\n",
    "    Returns:\n",
    "        list of str: Generated outputs corresponding to each input prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define sampling parameters\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    # Generate responses\n",
    "    outputs = llm.generate(prompts, sampling_params)\n",
    "    \n",
    "    # Extract text responses\n",
    "    return [output.outputs[0].text for output in outputs]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example prompts\n",
    "    prompts = [\n",
    "        \"Write a short story about a space explorer.\",\n",
    "        \"Explain the concept of quantum entanglement in simple terms.\",\n",
    "        \"Generate a creative recipe using chocolate and strawberries.\"\n",
    "    ] * 10\n",
    "    \n",
    "    batch_size = 2  # Adjust based on GPU memory\n",
    "    csv_filename = \"responses.csv\"\n",
    "    \n",
    "    # Write CSV header\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Prompt\", \"Response\"])\n",
    "    \n",
    "    # Process in batches and save results\n",
    "    for batch in batchify(prompts, batch_size):\n",
    "        responses = generate_responses(batch, temperature=0.7, top_p=0.9, max_tokens=150)\n",
    "        save_to_csv(csv_filename, batch, responses)\n",
    "    \n",
    "    print(f\"Responses saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(\"responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Zara Blackwood was a renowned space e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy boxes, one in New Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Chocolate Strawberry Tartlets:\\nIngredients:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Jameson stood on the bridge of his sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy cars that are connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Strawberry Chocolate Tart with Caramelized Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Zara Blackwood gazed out at the stars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy cars, one red and on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Strawberry Shortcake with Chocolate Mousse an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Orion Blackwood stood on the edge of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy cars that are connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Chocolate Strawberry Shortcake is a classic d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Jameson \"Jim\" Thompson, a seasoned as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy cars that are connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Chocolate-Dipped Strawberry Salad with Balsam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Jameson stood at the helm of his spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy cars that are connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Chocolate and strawberries are a classic comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Jameson gazed out the viewport of his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two dancers, Alice and Bob, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>\\n\\n**Strawberry Chocolate Mousse Cake**\\n\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain James \"Hawk\" Hawkins, a seasoned astr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you're at a party and you're holding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Chocolate and strawberry is a classic combina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Jameson gazed out at the stars, his e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you're sitting in a room with your fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Strawberry Chocolate Mousse Cake is a rich an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Write a short story about a space explorer.</td>\n",
       "      <td>Captain Jameson stood at the edge of the spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td>Imagine you have two toy cars that are connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Generate a creative recipe using chocolate and...</td>\n",
       "      <td>Strawberry-Balsamic Glazed Pork Chops with Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Prompt  \\\n",
       "0         Write a short story about a space explorer.   \n",
       "1   Explain the concept of quantum entanglement in...   \n",
       "2   Generate a creative recipe using chocolate and...   \n",
       "3         Write a short story about a space explorer.   \n",
       "4   Explain the concept of quantum entanglement in...   \n",
       "5   Generate a creative recipe using chocolate and...   \n",
       "6         Write a short story about a space explorer.   \n",
       "7   Explain the concept of quantum entanglement in...   \n",
       "8   Generate a creative recipe using chocolate and...   \n",
       "9         Write a short story about a space explorer.   \n",
       "10  Explain the concept of quantum entanglement in...   \n",
       "11  Generate a creative recipe using chocolate and...   \n",
       "12        Write a short story about a space explorer.   \n",
       "13  Explain the concept of quantum entanglement in...   \n",
       "14  Generate a creative recipe using chocolate and...   \n",
       "15        Write a short story about a space explorer.   \n",
       "16  Explain the concept of quantum entanglement in...   \n",
       "17  Generate a creative recipe using chocolate and...   \n",
       "18        Write a short story about a space explorer.   \n",
       "19  Explain the concept of quantum entanglement in...   \n",
       "20  Generate a creative recipe using chocolate and...   \n",
       "21        Write a short story about a space explorer.   \n",
       "22  Explain the concept of quantum entanglement in...   \n",
       "23  Generate a creative recipe using chocolate and...   \n",
       "24        Write a short story about a space explorer.   \n",
       "25  Explain the concept of quantum entanglement in...   \n",
       "26  Generate a creative recipe using chocolate and...   \n",
       "27        Write a short story about a space explorer.   \n",
       "28  Explain the concept of quantum entanglement in...   \n",
       "29  Generate a creative recipe using chocolate and...   \n",
       "\n",
       "                                             Response  \n",
       "0    Captain Zara Blackwood was a renowned space e...  \n",
       "1    Imagine you have two toy boxes, one in New Yo...  \n",
       "2    Chocolate Strawberry Tartlets:\\nIngredients:\\...  \n",
       "3    Captain Jameson stood on the bridge of his sh...  \n",
       "4    Imagine you have two toy cars that are connec...  \n",
       "5    Strawberry Chocolate Tart with Caramelized Pe...  \n",
       "6    Captain Zara Blackwood gazed out at the stars...  \n",
       "7    Imagine you have two toy cars, one red and on...  \n",
       "8    Strawberry Shortcake with Chocolate Mousse an...  \n",
       "9    Captain Orion Blackwood stood on the edge of ...  \n",
       "10   Imagine you have two toy cars that are connec...  \n",
       "11   Chocolate Strawberry Shortcake is a classic d...  \n",
       "12   Captain Jameson \"Jim\" Thompson, a seasoned as...  \n",
       "13   Imagine you have two toy cars that are connec...  \n",
       "14   Chocolate-Dipped Strawberry Salad with Balsam...  \n",
       "15   Captain Jameson stood at the helm of his spac...  \n",
       "16   Imagine you have two toy cars that are connec...  \n",
       "17   Chocolate and strawberries are a classic comb...  \n",
       "18   Captain Jameson gazed out the viewport of his...  \n",
       "19   Imagine you have two dancers, Alice and Bob, ...  \n",
       "20   \\n\\n**Strawberry Chocolate Mousse Cake**\\n\\nI...  \n",
       "21   Captain James \"Hawk\" Hawkins, a seasoned astr...  \n",
       "22   Imagine you're at a party and you're holding ...  \n",
       "23   Chocolate and strawberry is a classic combina...  \n",
       "24   Captain Jameson gazed out at the stars, his e...  \n",
       "25   Imagine you're sitting in a room with your fr...  \n",
       "26   Strawberry Chocolate Mousse Cake is a rich an...  \n",
       "27   Captain Jameson stood at the edge of the spac...  \n",
       "28   Imagine you have two toy cars that are connec...  \n",
       "29   Strawberry-Balsamic Glazed Pork Chops with Ch...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Captain Zara Blackwood was a renowned space explorer who had spent her entire career studying the mysteries of the cosmos. She had explored countless worlds, discovered new planets, and encountered alien species. But despite all her success, Zara felt a sense of restlessness, a feeling that there was still so much to explore, so many secrets to uncover.\\n\\nOne day, Zara received a cryptic message from an unknown sender, hinting at the existence of a long-lost planet on the edge of the galaxy. The message read: \"Meet me at the old observatory on planet Xylophia-IV at midnight. Come alone.\"\\n\\nZara\\'s curiosity was piqued, and she knew she had to investigate. She assembled her trust'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"Response\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
