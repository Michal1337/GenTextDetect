{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class FineTuneClassifier(nn.Module):\n",
    "    def __init__(self, base_model_path: str, num_labels: int) -> None:\n",
    "        super(FineTuneClassifier, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(base_model_path)\n",
    "\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Linear(self.base_model.config.hidden_size * 2, num_labels)\n",
    "\n",
    "    @classmethod\n",
    "    def from_classifier_head(\n",
    "        cls, base_model_path: str, path: str, num_labels: int\n",
    "    ) -> nn.Module:\n",
    "        model = cls(base_model_path, num_labels)\n",
    "        model.classifier.load_state_dict(torch.load(path))\n",
    "        return model\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.tensor, attention_mask: torch.tensor\n",
    "    ) -> torch.tensor:\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        B, T, C = outputs.logits.shape\n",
    "\n",
    "        all_tokens_hidden = outputs.logits  # (B, T, C)\n",
    "        last_token_hidden = outputs.logits[:, -1, :]  # (B, C)\n",
    "        last_token_hidden = last_token_hidden.unsqueeze(1).expand(B, T, C)\n",
    "\n",
    "        combined_representation = torch.cat(\n",
    "            (all_tokens_hidden, last_token_hidden), dim=-1\n",
    "        )\n",
    "        logits = self.classifier(combined_representation)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class BaselineClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        num_layers: int,\n",
    "        nhead: int,\n",
    "        max_seq_length: int,\n",
    "        vocab_size: int,\n",
    "        pad_token_id: int,\n",
    "        num_labels: int,\n",
    "    ) -> None:\n",
    "        super(BaselineClassifier, self).__init__()\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.token_embedding = nn.Embedding(\n",
    "            vocab_size, d_model, padding_idx=pad_token_id\n",
    "        )\n",
    "        self.pos_embedding = nn.Embedding(max_seq_length, d_model)\n",
    "        decoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(decoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model * 2, num_labels)\n",
    "\n",
    "    def forward(self, token_ids: torch.tensor) -> torch.tensor:\n",
    "        batch_size, seq_len = token_ids.shape\n",
    "\n",
    "        token_emb = self.token_embedding(token_ids)\n",
    "        pos_ids = torch.arange(seq_len, device=token_ids.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "        embeddings = token_emb + pos_emb\n",
    "\n",
    "        causal_mask = torch.triu(\n",
    "            torch.ones(seq_len, seq_len, device=token_ids.device, dtype=torch.bool),\n",
    "            diagonal=1,\n",
    "        )\n",
    "\n",
    "        pad_mask = token_ids.eq(self.pad_token_id)  # shape: (batch_size, seq_len)\n",
    "\n",
    "        output = self.transformer(\n",
    "            embeddings, mask=causal_mask, src_key_padding_mask=pad_mask\n",
    "        )\n",
    "\n",
    "        B, T, C = output.shape\n",
    "        all_tokens_hidden = output  # (B, T, C)\n",
    "        last_token_hidden = output[:, -1, :]  # (B, C)\n",
    "        last_token_hidden = last_token_hidden.unsqueeze(1).expand(B, T, C)\n",
    "\n",
    "        combined_representation = torch.cat(\n",
    "            (all_tokens_hidden, last_token_hidden), dim=-1\n",
    "        )\n",
    "        logits = self.classifier(combined_representation)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "BASELINE_MODELS: Dict[str, Dict[str, int]] = {\n",
    "    \"mini\": {\n",
    "        \"d_model\": 64,\n",
    "        \"num_layers\": 4,\n",
    "        \"num_heads\": 4,\n",
    "        \"max_len\": 16_384,\n",
    "    },\n",
    "    \"small\": {\n",
    "        \"d_model\": 510,\n",
    "        \"num_layers\": 8,\n",
    "        \"num_heads\": 6,\n",
    "        \"max_len\": 16_384,\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"d_model\": 1344,\n",
    "        \"num_layers\": 24,\n",
    "        \"num_heads\": 16,\n",
    "        \"max_len\": 16_384,\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"d_model\": 1824,\n",
    "        \"num_layers\": 36,\n",
    "        \"num_heads\": 24,\n",
    "        \"max_len\": 16_384,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp():\n",
    "    for name, config in BASELINE_MODELS.items():\n",
    "        d_model = config[\"d_model\"]\n",
    "        num_layers = config[\"num_layers\"]\n",
    "        nhead = config[\"num_heads\"]\n",
    "        max_seq_length = config[\"max_len\"]\n",
    "        vocab_size = 130_000\n",
    "        pad_token_id = 0\n",
    "        num_labels = 2\n",
    "\n",
    "        model = BaselineClassifier(\n",
    "            d_model,\n",
    "            num_layers,\n",
    "            nhead,\n",
    "            max_seq_length,\n",
    "            vocab_size,\n",
    "            pad_token_id,\n",
    "            num_labels,\n",
    "        )\n",
    "        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        emb_params = vocab_size * d_model\n",
    "\n",
    "        model.cuda()\n",
    "        used_memory = torch.cuda.memory_allocated(device=torch.device(\"cuda:0\"))\n",
    "        print(f\"Model: {name}, Total Parameters: {total_params / 1e6:.2f}M, % emb parameters: {emb_params/total_params}\")\n",
    "        print(f\"Active params: {(total_params - emb_params) / 1e6:.2f}M, emb params: {emb_params / 1e6:.2f}M\")\n",
    "        print(f\"Used VRAM: {used_memory / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nyt-comments</td>\n",
       "      <td>human</td>\n",
       "      <td>4223213</td>\n",
       "      <td>18713462</td>\n",
       "      <td>75699056</td>\n",
       "      <td>1418028952</td>\n",
       "      <td>367081295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogs</td>\n",
       "      <td>human</td>\n",
       "      <td>576731</td>\n",
       "      <td>8328335</td>\n",
       "      <td>11967700</td>\n",
       "      <td>557323671</td>\n",
       "      <td>164358740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raid</td>\n",
       "      <td>human</td>\n",
       "      <td>138244</td>\n",
       "      <td>1808789</td>\n",
       "      <td>7756169</td>\n",
       "      <td>215270586</td>\n",
       "      <td>95663743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural-questions</td>\n",
       "      <td>human</td>\n",
       "      <td>231628</td>\n",
       "      <td>544546</td>\n",
       "      <td>4821294</td>\n",
       "      <td>52668992</td>\n",
       "      <td>14758408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>writingprompts</td>\n",
       "      <td>human</td>\n",
       "      <td>303140</td>\n",
       "      <td>13802625</td>\n",
       "      <td>4407470</td>\n",
       "      <td>721933659</td>\n",
       "      <td>209316368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data  model  num_samples  num_sentences  num_words  \\\n",
       "0       nyt-comments  human      4223213       18713462   75699056   \n",
       "1              blogs  human       576731        8328335   11967700   \n",
       "2               raid  human       138244        1808789    7756169   \n",
       "3  natural-questions  human       231628         544546    4821294   \n",
       "4     writingprompts  human       303140       13802625    4407470   \n",
       "\n",
       "    num_chars  num_tokens  \n",
       "0  1418028952   367081295  \n",
       "1   557323671   164358740  \n",
       "2   215270586    95663743  \n",
       "3    52668992    14758408  \n",
       "4   721933659   209316368  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/stats/data_stats_master.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogs</td>\n",
       "      <td>576731</td>\n",
       "      <td>8328335</td>\n",
       "      <td>11967700</td>\n",
       "      <td>164358740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>essays</td>\n",
       "      <td>2638</td>\n",
       "      <td>123010</td>\n",
       "      <td>67709</td>\n",
       "      <td>1910966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural-questions</td>\n",
       "      <td>231628</td>\n",
       "      <td>544546</td>\n",
       "      <td>4821294</td>\n",
       "      <td>14758408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>15813</td>\n",
       "      <td>21318</td>\n",
       "      <td>316972</td>\n",
       "      <td>421258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nyt-comments</td>\n",
       "      <td>4223213</td>\n",
       "      <td>18713462</td>\n",
       "      <td>75699056</td>\n",
       "      <td>367081295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raid</td>\n",
       "      <td>138244</td>\n",
       "      <td>1808789</td>\n",
       "      <td>7756169</td>\n",
       "      <td>95663743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reddit</td>\n",
       "      <td>655484</td>\n",
       "      <td>1817797</td>\n",
       "      <td>11192328</td>\n",
       "      <td>32554655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tweets</td>\n",
       "      <td>389916</td>\n",
       "      <td>735759</td>\n",
       "      <td>4405208</td>\n",
       "      <td>8375173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>writingprompts</td>\n",
       "      <td>303140</td>\n",
       "      <td>13802625</td>\n",
       "      <td>4407470</td>\n",
       "      <td>209316368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xsum</td>\n",
       "      <td>226394</td>\n",
       "      <td>4298218</td>\n",
       "      <td>5268988</td>\n",
       "      <td>105941910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data  num_samples  num_sentences  num_words  num_tokens\n",
       "1              blogs       576731        8328335   11967700   164358740\n",
       "5             essays         2638         123010      67709     1910966\n",
       "3  natural-questions       231628         544546    4821294    14758408\n",
       "6       nyt-articles        15813          21318     316972      421258\n",
       "0       nyt-comments      4223213       18713462   75699056   367081295\n",
       "2               raid       138244        1808789    7756169    95663743\n",
       "8             reddit       655484        1817797   11192328    32554655\n",
       "7             tweets       389916         735759    4405208     8375173\n",
       "4     writingprompts       303140       13802625    4407470   209316368\n",
       "9               xsum       226394        4298218    5268988   105941910"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model\"] == \"human\"][[\"data\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_tokens\"]].sort_values(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogs</td>\n",
       "      <td>1182270</td>\n",
       "      <td>21203478</td>\n",
       "      <td>42920004</td>\n",
       "      <td>407024467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essays</td>\n",
       "      <td>58036</td>\n",
       "      <td>2765379</td>\n",
       "      <td>1685250</td>\n",
       "      <td>39439565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natural-questions</td>\n",
       "      <td>292083</td>\n",
       "      <td>866273</td>\n",
       "      <td>7906504</td>\n",
       "      <td>22504808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>347885</td>\n",
       "      <td>2165238</td>\n",
       "      <td>11276035</td>\n",
       "      <td>63994699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nyt-comments</td>\n",
       "      <td>8657565</td>\n",
       "      <td>36261431</td>\n",
       "      <td>175669667</td>\n",
       "      <td>746779789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>raid</td>\n",
       "      <td>864020</td>\n",
       "      <td>10784312</td>\n",
       "      <td>36630232</td>\n",
       "      <td>332672268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reddit</td>\n",
       "      <td>3408276</td>\n",
       "      <td>14035768</td>\n",
       "      <td>91421960</td>\n",
       "      <td>340245625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tweets</td>\n",
       "      <td>3665193</td>\n",
       "      <td>8117363</td>\n",
       "      <td>44659891</td>\n",
       "      <td>117976085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>writingprompts</td>\n",
       "      <td>621437</td>\n",
       "      <td>23319770</td>\n",
       "      <td>14339509</td>\n",
       "      <td>399446147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xsum</td>\n",
       "      <td>939528</td>\n",
       "      <td>12847522</td>\n",
       "      <td>26403940</td>\n",
       "      <td>360435457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data  num_samples  num_sentences  num_words  num_tokens\n",
       "0              blogs      1182270       21203478   42920004   407024467\n",
       "1             essays        58036        2765379    1685250    39439565\n",
       "2  natural-questions       292083         866273    7906504    22504808\n",
       "3       nyt-articles       347885        2165238   11276035    63994699\n",
       "4       nyt-comments      8657565       36261431  175669667   746779789\n",
       "5               raid       864020       10784312   36630232   332672268\n",
       "6             reddit      3408276       14035768   91421960   340245625\n",
       "7             tweets      3665193        8117363   44659891   117976085\n",
       "8     writingprompts       621437       23319770   14339509   399446147\n",
       "9               xsum       939528       12847522   26403940   360435457"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"data\").sum().reset_index()[[\"data\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_tokens\"]].sort_values(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data             blogsessaysnatural-questionsnyt-articlesnyt-co...\n",
       "num_samples                                               20036293\n",
       "num_sentences                                            132366534\n",
       "num_words                                                452912992\n",
       "num_tokens                                              2830518910\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"data\").sum().reset_index()[[\"data\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_tokens\"]].sort_values(\"data\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Falcon3-3B-Instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>3101084</td>\n",
       "      <td>13685350</td>\n",
       "      <td>70997241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Falcon3-7B-Instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>3137392</td>\n",
       "      <td>13173150</td>\n",
       "      <td>70783667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>628962</td>\n",
       "      <td>3024230</td>\n",
       "      <td>16408956</td>\n",
       "      <td>73421205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>640759</td>\n",
       "      <td>3045728</td>\n",
       "      <td>17141415</td>\n",
       "      <td>75775399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta-Llama-3.1-70B-Instruct-AWQ-INT4</td>\n",
       "      <td>640750</td>\n",
       "      <td>2994366</td>\n",
       "      <td>15242777</td>\n",
       "      <td>67950245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meta-Llama-3.3-70B-Instruct-AWQ-INT4</td>\n",
       "      <td>640766</td>\n",
       "      <td>2861116</td>\n",
       "      <td>17991535</td>\n",
       "      <td>72319091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>629186</td>\n",
       "      <td>5622574</td>\n",
       "      <td>14260174</td>\n",
       "      <td>96603355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>629186</td>\n",
       "      <td>4600976</td>\n",
       "      <td>11064530</td>\n",
       "      <td>89254622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Phi-3-medium-128k-instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>4817462</td>\n",
       "      <td>18533613</td>\n",
       "      <td>104452491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Phi-3-mini-128k-instruct</td>\n",
       "      <td>640760</td>\n",
       "      <td>5390971</td>\n",
       "      <td>14991412</td>\n",
       "      <td>92989442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phi-3-small-128k-instruct</td>\n",
       "      <td>631741</td>\n",
       "      <td>4391729</td>\n",
       "      <td>15937306</td>\n",
       "      <td>108001280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Phi-3.5-mini-instruct</td>\n",
       "      <td>629170</td>\n",
       "      <td>7116477</td>\n",
       "      <td>18601219</td>\n",
       "      <td>134161628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Phi-4-mini-instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>4493945</td>\n",
       "      <td>15259110</td>\n",
       "      <td>85575122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2-72B-Instruct-AWQ</td>\n",
       "      <td>629185</td>\n",
       "      <td>3879475</td>\n",
       "      <td>11146398</td>\n",
       "      <td>83617822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>3630558</td>\n",
       "      <td>12737224</td>\n",
       "      <td>84738592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>2969730</td>\n",
       "      <td>11705178</td>\n",
       "      <td>62298346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>2971931</td>\n",
       "      <td>12993535</td>\n",
       "      <td>61079140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qwen2.5-72B-Instruct-AWQ</td>\n",
       "      <td>629186</td>\n",
       "      <td>3110547</td>\n",
       "      <td>11518826</td>\n",
       "      <td>64104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>629186</td>\n",
       "      <td>3164651</td>\n",
       "      <td>12151482</td>\n",
       "      <td>63915062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>640767</td>\n",
       "      <td>2426004</td>\n",
       "      <td>11245029</td>\n",
       "      <td>47038459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>human</td>\n",
       "      <td>6763201</td>\n",
       "      <td>50193859</td>\n",
       "      <td>125902894</td>\n",
       "      <td>1000382516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>phi-4</td>\n",
       "      <td>629186</td>\n",
       "      <td>5421729</td>\n",
       "      <td>41221879</td>\n",
       "      <td>221059837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model  num_samples  num_sentences  \\\n",
       "0                    Falcon3-3B-Instruct       629186        3101084   \n",
       "1                    Falcon3-7B-Instruct       629186        3137392   \n",
       "2                  Llama-3.1-8B-Instruct       628962        3024230   \n",
       "3                  Llama-3.2-3B-Instruct       640759        3045728   \n",
       "4   Meta-Llama-3.1-70B-Instruct-AWQ-INT4       640750        2994366   \n",
       "5   Meta-Llama-3.3-70B-Instruct-AWQ-INT4       640766        2861116   \n",
       "6             Ministral-8B-Instruct-2410       629186        5622574   \n",
       "7             Mistral-Nemo-Instruct-2407       629186        4600976   \n",
       "8             Phi-3-medium-128k-instruct       629186        4817462   \n",
       "9               Phi-3-mini-128k-instruct       640760        5390971   \n",
       "10             Phi-3-small-128k-instruct       631741        4391729   \n",
       "11                 Phi-3.5-mini-instruct       629170        7116477   \n",
       "12                   Phi-4-mini-instruct       629186        4493945   \n",
       "13                Qwen2-72B-Instruct-AWQ       629185        3879475   \n",
       "14                     Qwen2-7B-Instruct       629186        3630558   \n",
       "15                  Qwen2.5-14B-Instruct       629186        2969730   \n",
       "16                   Qwen2.5-3B-Instruct       629186        2971931   \n",
       "17              Qwen2.5-72B-Instruct-AWQ       629186        3110547   \n",
       "18                   Qwen2.5-7B-Instruct       629186        3164651   \n",
       "19               gpt-4.1-nano-2025-04-14       640767        2426004   \n",
       "20                                 human      6763201       50193859   \n",
       "21                                 phi-4       629186        5421729   \n",
       "\n",
       "    num_words  num_tokens  \n",
       "0    13685350    70997241  \n",
       "1    13173150    70783667  \n",
       "2    16408956    73421205  \n",
       "3    17141415    75775399  \n",
       "4    15242777    67950245  \n",
       "5    17991535    72319091  \n",
       "6    14260174    96603355  \n",
       "7    11064530    89254622  \n",
       "8    18533613   104452491  \n",
       "9    14991412    92989442  \n",
       "10   15937306   108001280  \n",
       "11   18601219   134161628  \n",
       "12   15259110    85575122  \n",
       "13   11146398    83617822  \n",
       "14   12737224    84738592  \n",
       "15   11705178    62298346  \n",
       "16   12993535    61079140  \n",
       "17   11518826    64104348  \n",
       "18   12151482    63915062  \n",
       "19   11245029    47038459  \n",
       "20  125902894  1000382516  \n",
       "21   41221879   221059837  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"model\").sum().reset_index()[[\"model\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model            Falcon3-3B-InstructFalcon3-7B-InstructLlama-3....\n",
       "num_samples                                               20036293\n",
       "num_sentences                                            132366534\n",
       "num_words                                                452912992\n",
       "num_tokens                                              2830518910\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"model\").sum().reset_index()[[\"model\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_tokens\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_human\"] = df[\"model\"].apply(lambda x: 1 if x == \"human\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_human</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13273092</td>\n",
       "      <td>82172675</td>\n",
       "      <td>327010098</td>\n",
       "      <td>1830136394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6763201</td>\n",
       "      <td>50193859</td>\n",
       "      <td>125902894</td>\n",
       "      <td>1000382516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_human  num_samples  num_sentences  num_words  num_tokens\n",
       "0         0     13273092       82172675  327010098  1830136394\n",
       "1         1      6763201       50193859  125902894  1000382516"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"is_human\").sum()[[\"num_samples\", \"num_sentences\", \"num_words\", \"num_tokens\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
