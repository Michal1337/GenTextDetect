{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\"\n",
    "LLMS: List[Tuple[str, str, Optional[str]]] = [\n",
    "    # Meta\n",
    "    (\"meta-llama/Llama-3.1-8B-Instruct\", MODEL_PATH + \"meta-llama/Llama-3.1-8B-Instruct\", None),\n",
    "    (\"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\", MODEL_PATH + \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\", \"awq\"),\n",
    "    (\"meta-llama/Llama-3.2-3B-Instruct\", MODEL_PATH + \"meta-llama/Llama-3.2-3B-Instruct\", None),\n",
    "    (\"ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4\", MODEL_PATH + \"ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4\", \"awq\"),\n",
    "    \n",
    "    # Microsoft\n",
    "    (\"microsoft/Phi-3-mini-128k-instruct\", MODEL_PATH + \"microsoft/Phi-3-mini-128k-instruct\", None),\n",
    "    (\"microsoft/Phi-3-small-128k-instruct\", MODEL_PATH + \"microsoft/Phi-3-small-128k-instruct\", None),\n",
    "    (\"microsoft/Phi-3-medium-128k-instruct\", MODEL_PATH + \"microsoft/Phi-3-medium-128k-instruct\", None),\n",
    "    (\"microsoft/Phi-3.5-mini-instruct\", MODEL_PATH + \"microsoft/Phi-3.5-mini-instruct\", None),\n",
    "    (\"microsoft/Phi-4-mini-instruct\", MODEL_PATH + \"microsoft/Phi-4-mini-instruct\", None),\n",
    "    (\"microsoft/phi-4\", MODEL_PATH + \"microsoft/phi-4\", None),\n",
    "    \n",
    "    # Mistral\n",
    "    (\"mistralai/Mistral-Nemo-Instruct-2407\", MODEL_PATH + \"mistralai/Mistral-Nemo-Instruct-2407\", None),\n",
    "    (\"mistralai/Ministral-8B-Instruct-2410\", MODEL_PATH + \"mistralai/Ministral-8B-Instruct-2410\", None),\n",
    "    \n",
    "    # Qwen\n",
    "    (\"Qwen/Qwen2-72B-Instruct-AWQ\", MODEL_PATH + \"Qwen/Qwen2-72B-Instruct-AWQ\", \"awq\"),\n",
    "    (\"Qwen/Qwen2-7B-Instruct\", MODEL_PATH + \"Qwen/Qwen2-7B-Instruct\", None),\n",
    "    (\"Qwen/Qwen2.5-72B-Instruct-AWQ\", MODEL_PATH + \"Qwen/Qwen2.5-72B-Instruct-AWQ\", \"awq\"),\n",
    "    (\"Qwen/Qwen2.5-14B-Instruct\", MODEL_PATH + \"Qwen/Qwen2.5-14B-Instruct\", None),\n",
    "    (\"Qwen/Qwen2.5-7B-Instruct\", MODEL_PATH + \"Qwen/Qwen2.5-7B-Instruct\", None),\n",
    "    (\"Qwen/Qwen2.5-3B-Instruct\", MODEL_PATH + \"Qwen/Qwen2.5-3B-Instruct\", None),\n",
    "    \n",
    "    # Falcon\n",
    "    (\"tiiuae/Falcon3-7B-Instruct\", MODEL_PATH + \"tiiuae/Falcon3-7B-Instruct\", None),\n",
    "    (\"tiiuae/Falcon3-3B-Instruct\", MODEL_PATH + \"tiiuae/Falcon3-3B-Instruct\", None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-3.1-8B-Instruct\n",
      "[128000, 9906, 11, 1268, 527, 499, 30] 7\n",
      "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\n",
      "[128000, 9906, 11, 1268, 527, 499, 30] 7\n",
      "meta-llama/Llama-3.2-3B-Instruct\n",
      "[128000, 9906, 11, 1268, 527, 499, 30] 7\n",
      "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4\n",
      "[128000, 9906, 11, 1268, 527, 499, 30] 7\n",
      "microsoft/Phi-3-mini-128k-instruct\n",
      "[15043, 29892, 920, 526, 366, 29973] 6\n",
      "microsoft/Phi-3-small-128k-instruct\n",
      "[9906, 11, 1268, 527, 499, 30] 6\n",
      "microsoft/Phi-3-medium-128k-instruct\n",
      "[15043, 29892, 920, 526, 366, 29973] 6\n",
      "microsoft/Phi-3.5-mini-instruct\n",
      "[15043, 29892, 920, 526, 366, 29973] 6\n",
      "microsoft/Phi-4-mini-instruct\n",
      "[13225, 11, 1495, 553, 481, 30] 6\n",
      "microsoft/phi-4\n",
      "[9906, 11, 1268, 527, 499, 30] 6\n",
      "mistralai/Mistral-Nemo-Instruct-2407\n",
      "[1, 22177, 1044, 2606, 1584, 1636, 1063] 7\n",
      "mistralai/Ministral-8B-Instruct-2410\n",
      "[1, 22177, 1044, 2606, 1584, 1636, 1063] 7\n",
      "Qwen/Qwen2-72B-Instruct-AWQ\n",
      "[9707, 11, 1246, 525, 498, 30] 6\n",
      "Qwen/Qwen2-7B-Instruct\n",
      "[9707, 11, 1246, 525, 498, 30] 6\n",
      "Qwen/Qwen2.5-72B-Instruct-AWQ\n",
      "[9707, 11, 1246, 525, 498, 30] 6\n",
      "Qwen/Qwen2.5-14B-Instruct\n",
      "[9707, 11, 1246, 525, 498, 30] 6\n",
      "Qwen/Qwen2.5-7B-Instruct\n",
      "[9707, 11, 1246, 525, 498, 30] 6\n",
      "Qwen/Qwen2.5-3B-Instruct\n",
      "[9707, 11, 1246, 525, 498, 30] 6\n",
      "tiiuae/Falcon3-7B-Instruct\n",
      "[13955, 2035, 2761, 2402, 2343, 2054] 6\n",
      "tiiuae/Falcon3-3B-Instruct\n",
      "[13955, 2035, 2761, 2402, 2343, 2054] 6\n"
     ]
    }
   ],
   "source": [
    "for model, path, quant in  LLMS:\n",
    "    print(model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "    print(tokenizer(\"Hello, how are you?\")[\"input_ids\"], len(tokenizer(\"Hello, how are you?\")[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
