{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_paths(folder_path, recursive=False):\n",
    "    if recursive:\n",
    "        # Walk through all subdirectories\n",
    "        file_paths = [os.path.join(root, file) \n",
    "                      for root, _, files in os.walk(folder_path) \n",
    "                      for file in files if file.endswith('.csv')]\n",
    "    else:\n",
    "        # Get files in the root folder only\n",
    "        file_paths = [os.path.join(folder_path, file) \n",
    "                      for file in os.listdir(folder_path) \n",
    "                      if file.endswith('.csv')]\n",
    "    \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>avg_sent_per_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogs</td>\n",
       "      <td>Phi-3-small-128k-instruct</td>\n",
       "      <td>28836</td>\n",
       "      <td>677403</td>\n",
       "      <td>903150</td>\n",
       "      <td>57362602</td>\n",
       "      <td>15187889</td>\n",
       "      <td>23.491573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogs</td>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>28836</td>\n",
       "      <td>447683</td>\n",
       "      <td>701052</td>\n",
       "      <td>42284112</td>\n",
       "      <td>10675655</td>\n",
       "      <td>15.525142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogs</td>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>28836</td>\n",
       "      <td>330384</td>\n",
       "      <td>391804</td>\n",
       "      <td>24062475</td>\n",
       "      <td>6315173</td>\n",
       "      <td>11.457345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blogs</td>\n",
       "      <td>Ministral-8B-Instruct-2410</td>\n",
       "      <td>28836</td>\n",
       "      <td>742094</td>\n",
       "      <td>929327</td>\n",
       "      <td>42635432</td>\n",
       "      <td>12117456</td>\n",
       "      <td>25.734984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blogs</td>\n",
       "      <td>Phi-3-medium-128k-instruct</td>\n",
       "      <td>28836</td>\n",
       "      <td>939614</td>\n",
       "      <td>1822958</td>\n",
       "      <td>71160696</td>\n",
       "      <td>18987094</td>\n",
       "      <td>32.584755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>essays</td>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>2638</td>\n",
       "      <td>91191</td>\n",
       "      <td>44632</td>\n",
       "      <td>4982535</td>\n",
       "      <td>1394185</td>\n",
       "      <td>34.568234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>essays</td>\n",
       "      <td>Phi-3.5-mini-instruct</td>\n",
       "      <td>2638</td>\n",
       "      <td>129167</td>\n",
       "      <td>73580</td>\n",
       "      <td>6103995</td>\n",
       "      <td>1806459</td>\n",
       "      <td>48.963988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>blogs</td>\n",
       "      <td>human</td>\n",
       "      <td>576774</td>\n",
       "      <td>8370715</td>\n",
       "      <td>9554000</td>\n",
       "      <td>560257945</td>\n",
       "      <td>165283569</td>\n",
       "      <td>14.512989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>human</td>\n",
       "      <td>15813</td>\n",
       "      <td>21318</td>\n",
       "      <td>272825</td>\n",
       "      <td>1759817</td>\n",
       "      <td>421260</td>\n",
       "      <td>1.348131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>essays</td>\n",
       "      <td>human</td>\n",
       "      <td>2638</td>\n",
       "      <td>123010</td>\n",
       "      <td>61180</td>\n",
       "      <td>6702708</td>\n",
       "      <td>1910971</td>\n",
       "      <td>46.630023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            data                       model  num_samples  num_sentences  \\\n",
       "0          blogs   Phi-3-small-128k-instruct        28836         677403   \n",
       "1          blogs       Llama-3.2-3B-Instruct        28836         447683   \n",
       "2          blogs        Qwen2.5-14B-Instruct        28836         330384   \n",
       "3          blogs  Ministral-8B-Instruct-2410        28836         742094   \n",
       "4          blogs  Phi-3-medium-128k-instruct        28836         939614   \n",
       "..           ...                         ...          ...            ...   \n",
       "58        essays        Qwen2.5-14B-Instruct         2638          91191   \n",
       "59        essays       Phi-3.5-mini-instruct         2638         129167   \n",
       "60         blogs                       human       576774        8370715   \n",
       "61  nyt-articles                       human        15813          21318   \n",
       "62        essays                       human         2638         123010   \n",
       "\n",
       "    num_words  num_chars  num_tokens  avg_sent_per_sample  \n",
       "0      903150   57362602    15187889            23.491573  \n",
       "1      701052   42284112    10675655            15.525142  \n",
       "2      391804   24062475     6315173            11.457345  \n",
       "3      929327   42635432    12117456            25.734984  \n",
       "4     1822958   71160696    18987094            32.584755  \n",
       "..        ...        ...         ...                  ...  \n",
       "58      44632    4982535     1394185            34.568234  \n",
       "59      73580    6103995     1806459            48.963988  \n",
       "60    9554000  560257945   165283569            14.512989  \n",
       "61     272825    1759817      421260             1.348131  \n",
       "62      61180    6702708     1910971            46.630023  \n",
       "\n",
       "[63 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main = pd.read_csv('../data/stats/data_stats_master.csv')\n",
    "df_main[\"avg_sent_per_sample\"] = df_main[\"num_sentences\"] / df_main[\"num_samples\"]\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_idx(max_tokens, batch_size, stats, df_main, cols_c0, save_path):\n",
    "\n",
    "    for ds in [\"blogs\", \"essays\", \"nyt-articles\"]:\n",
    "        mask_c0 = (df_main[\"data\"].values == ds) & (df_main[\"model\"].isin(cols_c0))\n",
    "        mask_c1 = (df_main[\"data\"].values == ds) & (~df_main[\"model\"].isin(cols_c0))\n",
    "        \n",
    "        df_main.loc[mask_c1, \"prob\"] = 1 / df_main.loc[mask_c1, \"avg_sent_per_sample\"] / (1 / df_main.loc[mask_c1, \"avg_sent_per_sample\"]).sum()\n",
    "        \n",
    "        avg_h = df_main.loc[mask_c0, \"avg_sent_per_sample\"].values[0]\n",
    "        avg_ai = (df_main.loc[mask_c1, \"avg_sent_per_sample\"] * df_main.loc[mask_c1, \"prob\"]).sum()\n",
    "        \n",
    "        c = 1 / (1 + avg_ai / avg_h)\n",
    "        p = 1 - c\n",
    "        \n",
    "        df_main.loc[mask_c1, \"prob\"] *= c\n",
    "        df_main.loc[mask_c0, \"prob\"] = p\n",
    "\n",
    "    weights = [\n",
    "        1 / (df_main.loc[df_main[\"data\"] == ds, \"avg_sent_per_sample\"] * df_main.loc[df_main[\"data\"] == ds, \"prob\"]).sum()\n",
    "        for ds in [\"blogs\", \"essays\", \"nyt-articles\"]\n",
    "    ]\n",
    "    probs = np.array(weights) / np.sum(weights)\n",
    "\n",
    "    total_tokens = 0\n",
    "    total_sentences = 0\n",
    "    total_samples = 0\n",
    "    cnt = 0\n",
    "    while total_tokens < max_tokens:\n",
    "        data = np.random.choice([\"blogs\", \"essays\", \"nyt-articles\"], p=probs)\n",
    "        tmp = df_main[(df_main[\"data\"] == data)]\n",
    "        model = np.random.choice(tmp[\"model\"], p=tmp[\"prob\"])\n",
    "\n",
    "        stat = stats[f\"{data}_{model}\"]\n",
    "\n",
    "        slct = stat.sample(n=batch_size)\n",
    "        stat.drop(slct.index, inplace=True)\n",
    "\n",
    "        total_tokens += slct.sum()[\"num_tokens\"]\n",
    "        total_sentences += slct.sum()[\"num_sentences\"]\n",
    "        total_samples += batch_size\n",
    "\n",
    "\n",
    "        # save data, model, slct.index to csv\n",
    "        slct[\"data\"] = data\n",
    "        slct[\"model\"] = model\n",
    "        slct.reset_index(inplace=True)\n",
    "        # slct.drop(columns=[\"num_sentences\", \"num_words\", \"num_chars\", \"num_tokens\"], inplace=True)\n",
    "        slct.to_csv(save_path, mode='a', header=not os.path.exists(save_path), index=False)\n",
    "\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print(f\"total_tokens: {total_tokens}, total_sentences: {total_sentences}, total_samples: {total_samples}\")\n",
    "\n",
    "    print(\n",
    "        f\"Final samples: {total_samples}, Final sentences: {total_sentences}, Final tokens: {total_tokens}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUMAN_PATH = \"../data/stats/data_human\"\n",
    "DATA_AI_PATH = \"../data/stats/data_ai\"\n",
    "DATASET_IDX_PATH = \"../data/datasets/test2_idx.csv\"\n",
    "paths = get_csv_paths(DATA_HUMAN_PATH) + get_csv_paths(DATA_AI_PATH, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dict({f\"{path.split(\"/\")[-1].split(\"_\")[0]}_{path.split(\"/\")[-1].split(\"_\")[1]}\": pd.read_csv(path) for path in paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 1e6\n",
    "total_tokens = 0\n",
    "total_sentences = 0\n",
    "total_samples = 0\n",
    "batch_size = 16\n",
    "cols_c0 = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final samples: 9488, Final sentences: 52319, Final tokens: 1013086\n"
     ]
    }
   ],
   "source": [
    "for ds in [\"blogs\", \"essays\", \"nyt-articles\"]:\n",
    "    mask_c0 = (df_main[\"data\"].values == ds) & (df_main[\"model\"].isin(cols_c0))\n",
    "    mask_c1 = (df_main[\"data\"].values == ds) & (~df_main[\"model\"].isin(cols_c0))\n",
    "    \n",
    "    df_main.loc[mask_c1, \"prob\"] = 1 / df_main.loc[mask_c1, \"avg_sent_per_sample\"] / (1 / df_main.loc[mask_c1, \"avg_sent_per_sample\"]).sum()\n",
    "    \n",
    "    avg_h = df_main.loc[mask_c0, \"avg_sent_per_sample\"].values[0]\n",
    "    avg_ai = (df_main.loc[mask_c1, \"avg_sent_per_sample\"] * df_main.loc[mask_c1, \"prob\"]).sum()\n",
    "    \n",
    "    c = 1 / (1 + avg_ai / avg_h)\n",
    "    p = 1 - c\n",
    "    \n",
    "    df_main.loc[mask_c1, \"prob\"] *= c\n",
    "    df_main.loc[mask_c0, \"prob\"] = p\n",
    "\n",
    "weights = [\n",
    "    1 / (df_main.loc[df_main[\"data\"] == ds, \"avg_sent_per_sample\"] * df_main.loc[df_main[\"data\"] == ds, \"prob\"]).sum()\n",
    "    for ds in [\"blogs\", \"essays\", \"nyt-articles\"]\n",
    "]\n",
    "probs = np.array(weights) / np.sum(weights)\n",
    "\n",
    "total_tokens = 0\n",
    "total_sentences = 0\n",
    "total_samples = 0\n",
    "cnt = 0\n",
    "while total_tokens < max_tokens:\n",
    "    data = np.random.choice([\"blogs\", \"essays\", \"nyt-articles\"], p=probs)\n",
    "    tmp = df_main[(df_main[\"data\"] == data)]\n",
    "    model = np.random.choice(tmp[\"model\"], p=tmp[\"prob\"])\n",
    "\n",
    "    stat = stats[f\"{data}_{model}\"]\n",
    "\n",
    "    slct = stat.sample(n=batch_size)\n",
    "    stat.drop(slct.index, inplace=True)\n",
    "\n",
    "    total_tokens += slct.sum()[\"num_tokens\"]\n",
    "    total_sentences += slct.sum()[\"num_sentences\"]\n",
    "    total_samples += batch_size\n",
    "\n",
    "\n",
    "    # save data, model, slct.index to csv\n",
    "    slct[\"data\"] = data\n",
    "    slct[\"model\"] = model\n",
    "    slct.reset_index(inplace=True)\n",
    "    # slct.drop(columns=[\"num_sentences\", \"num_words\", \"num_chars\", \"num_tokens\"], inplace=True)\n",
    "    slct.to_csv(DATASET_IDX_PATH, mode='a', header=not os.path.exists(DATASET_IDX_PATH), index=False)\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt % 1000 == 0:\n",
    "        print(f\"total_tokens: {total_tokens}, total_sentences: {total_sentences}, total_samples: {total_samples}\")\n",
    "\n",
    "print(\n",
    "    f\"Final samples: {total_samples}, Final sentences: {total_sentences}, Final tokens: {total_tokens}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 1829673, total_sentences: 91767, total_samples: 16000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_dataset_idx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_main\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_main\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_c0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET_IDX_PATH\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 35\u001b[0m, in \u001b[0;36mcreate_dataset_idx\u001b[0;34m(max_tokens, batch_size, stats, df_main, col_c0, save_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(tmp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], p\u001b[38;5;241m=\u001b[39mtmp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     33\u001b[0m stat \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 35\u001b[0m slct \u001b[38;5;241m=\u001b[39m \u001b[43mstat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m stat\u001b[38;5;241m.\u001b[39mdrop(slct\u001b[38;5;241m.\u001b[39mindex, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m total_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m slct\u001b[38;5;241m.\u001b[39msum()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:6118\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1024\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "create_dataset_idx(\n",
    "    max_tokens=max_tokens,\n",
    "    batch_size=batch_size,\n",
    "    stats=stats,\n",
    "    df_main=df_main,\n",
    "    col_c0=\"human\",\n",
    "    save_path=DATASET_IDX_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8956</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3736</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3133</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>29</td>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10762</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>124</td>\n",
       "      <td>27</td>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13421</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>102</td>\n",
       "      <td>26</td>\n",
       "      <td>nyt-articles</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  num_sentences  num_words  num_chars  num_tokens          data  model\n",
       "0   8956              1         21         89          23  nyt-articles  human\n",
       "1   3736              2          1         41          14  nyt-articles  human\n",
       "2   3133              1         19         83          29  nyt-articles  human\n",
       "3  10762              1         22        124          27  nyt-articles  human\n",
       "4  13421              2         14        102          26  nyt-articles  human"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_IDX_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_human\"] = np.where(df[\"model\"] == \"human\", \"human\", \"ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_human</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>193876359</td>\n",
       "      <td>233805</td>\n",
       "      <td>650686</td>\n",
       "      <td>22550325</td>\n",
       "      <td>5322657</td>\n",
       "      <td>nyt-articlesnyt-articlesnyt-articlesnyt-articl...</td>\n",
       "      <td>Qwen2-7B-InstructQwen2-7B-InstructQwen2-7B-Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>2165432127</td>\n",
       "      <td>255290</td>\n",
       "      <td>1180776</td>\n",
       "      <td>17303355</td>\n",
       "      <td>4677614</td>\n",
       "      <td>nyt-articlesnyt-articlesnyt-articlesnyt-articl...</td>\n",
       "      <td>humanhumanhumanhumanhumanhumanhumanhumanhumanh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index  num_sentences  num_words  num_chars  num_tokens  \\\n",
       "is_human                                                                \n",
       "ai         193876359         233805     650686   22550325     5322657   \n",
       "human     2165432127         255290    1180776   17303355     4677614   \n",
       "\n",
       "                                                       data  \\\n",
       "is_human                                                      \n",
       "ai        nyt-articlesnyt-articlesnyt-articlesnyt-articl...   \n",
       "human     nyt-articlesnyt-articlesnyt-articlesnyt-articl...   \n",
       "\n",
       "                                                      model  \n",
       "is_human                                                     \n",
       "ai        Qwen2-7B-InstructQwen2-7B-InstructQwen2-7B-Ins...  \n",
       "human     humanhumanhumanhumanhumanhumanhumanhumanhumanh...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"is_human\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th>is_human</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">blogs</th>\n",
       "      <th>ai</th>\n",
       "      <td>66290103</td>\n",
       "      <td>77207</td>\n",
       "      <td>165177</td>\n",
       "      <td>6004061</td>\n",
       "      <td>1633273</td>\n",
       "      <td>Qwen2.5-7B-InstructQwen2.5-7B-InstructQwen2.5-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>1686301471</td>\n",
       "      <td>84363</td>\n",
       "      <td>95677</td>\n",
       "      <td>5621581</td>\n",
       "      <td>1654614</td>\n",
       "      <td>humanhumanhumanhumanhumanhumanhumanhumanhumanh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">essays</th>\n",
       "      <th>ai</th>\n",
       "      <td>2718590</td>\n",
       "      <td>76446</td>\n",
       "      <td>30331</td>\n",
       "      <td>4363208</td>\n",
       "      <td>1197528</td>\n",
       "      <td>phi-4phi-4phi-4phi-4phi-4phi-4phi-4phi-4phi-4p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>2534817</td>\n",
       "      <td>90067</td>\n",
       "      <td>46643</td>\n",
       "      <td>4993122</td>\n",
       "      <td>1420840</td>\n",
       "      <td>humanhumanhumanhumanhumanhumanhumanhumanhumanh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">nyt-articles</th>\n",
       "      <th>ai</th>\n",
       "      <td>124867666</td>\n",
       "      <td>80152</td>\n",
       "      <td>455178</td>\n",
       "      <td>12183056</td>\n",
       "      <td>2491856</td>\n",
       "      <td>Qwen2-7B-InstructQwen2-7B-InstructQwen2-7B-Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>476595839</td>\n",
       "      <td>80860</td>\n",
       "      <td>1038456</td>\n",
       "      <td>6688652</td>\n",
       "      <td>1602160</td>\n",
       "      <td>humanhumanhumanhumanhumanhumanhumanhumanhumanh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            index  num_sentences  num_words  num_chars  \\\n",
       "data         is_human                                                    \n",
       "blogs        ai          66290103          77207     165177    6004061   \n",
       "             human     1686301471          84363      95677    5621581   \n",
       "essays       ai           2718590          76446      30331    4363208   \n",
       "             human        2534817          90067      46643    4993122   \n",
       "nyt-articles ai         124867666          80152     455178   12183056   \n",
       "             human      476595839          80860    1038456    6688652   \n",
       "\n",
       "                       num_tokens  \\\n",
       "data         is_human               \n",
       "blogs        ai           1633273   \n",
       "             human        1654614   \n",
       "essays       ai           1197528   \n",
       "             human        1420840   \n",
       "nyt-articles ai           2491856   \n",
       "             human        1602160   \n",
       "\n",
       "                                                                   model  \n",
       "data         is_human                                                     \n",
       "blogs        ai        Qwen2.5-7B-InstructQwen2.5-7B-InstructQwen2.5-...  \n",
       "             human     humanhumanhumanhumanhumanhumanhumanhumanhumanh...  \n",
       "essays       ai        phi-4phi-4phi-4phi-4phi-4phi-4phi-4phi-4phi-4p...  \n",
       "             human     humanhumanhumanhumanhumanhumanhumanhumanhumanh...  \n",
       "nyt-articles ai        Qwen2-7B-InstructQwen2-7B-InstructQwen2-7B-Ins...  \n",
       "             human     humanhumanhumanhumanhumanhumanhumanhumanhumanh...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"data\", \"is_human\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
