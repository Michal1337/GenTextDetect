{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"o200k_base\") #cl100k_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_paths(folder_path, recursive=False):\n",
    "    if recursive:\n",
    "        # Walk through all subdirectories\n",
    "        file_paths = [os.path.join(root, file) \n",
    "                      for root, _, files in os.walk(folder_path) \n",
    "                      for file in files if file.endswith('.csv')]\n",
    "    else:\n",
    "        # Get files in the root folder only\n",
    "        file_paths = [os.path.join(folder_path, file) \n",
    "                      for file in os.listdir(folder_path) \n",
    "                      if file.endswith('.csv')]\n",
    "    \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(texts):\n",
    "    results = []\n",
    "    total_sentences, total_words, total_chars, total_tokens = 0, 0, 0, 0\n",
    "    total_samples = len(texts)\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        text_chars = 0\n",
    "        text_tokens = enc.encode(text)\n",
    "        sentences = sent_tokenize(text)\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            text_chars += sum([len(word) for word in words])\n",
    "\n",
    "        total_sentences += len(sentences)\n",
    "        total_words += len(words)\n",
    "        total_chars += text_chars\n",
    "        total_tokens += len(text_tokens)\n",
    "\n",
    "        results.append([len(sentences), len(words), text_chars, len(text_tokens)])\n",
    "    return results, total_samples, total_sentences, total_words, total_chars, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUMAN_PATH = \"../data/data_human\"\n",
    "DATA_AI_PATH = \"../data/data_ai\"\n",
    "STATS_PATH = \"../data/stats/\"\n",
    "MASTER_STATS_PATH = \"../data/stats/data_stats_master.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_csv_paths(DATA_HUMAN_PATH) + get_csv_paths(DATA_AI_PATH, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226394/226394 [11:38<00:00, 323.96it/s]\n",
      "100%|██████████| 303140/303140 [26:02<00:00, 193.96it/s]\n",
      "100%|██████████| 138244/138244 [06:17<00:00, 366.54it/s]\n",
      "100%|██████████| 640908/640908 [01:34<00:00, 6795.06it/s]\n",
      "100%|██████████| 655485/655485 [03:59<00:00, 2738.57it/s]\n",
      "100%|██████████| 4223213/4223213 [45:59<00:00, 1530.46it/s] \n",
      "100%|██████████| 576774/576774 [16:54<00:00, 568.74it/s] \n",
      "100%|██████████| 15813/15813 [00:02<00:00, 6377.01it/s]\n",
      "100%|██████████| 2638/2638 [00:11<00:00, 233.23it/s]\n",
      "100%|██████████| 384/384 [00:00<00:00, 443.82it/s]\n",
      "100%|██████████| 384/384 [00:00<00:00, 1134.20it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 285.26it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 4104.85it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 1517.84it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 2699.91it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 1424.49it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 558.58it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 409.50it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(MASTER_STATS_PATH, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"data\", \"model\", \"num_samples\", \"num_sentences\", \"num_words\", \"num_chars\", \"num_tokens\"])\n",
    "\n",
    "for path in paths:\n",
    "    if path.split(\"_\")[-1] == \"human.csv\":\n",
    "        stats_path = os.path.join(STATS_PATH, path.split(\"/\")[-2], path.split(\"/\")[-1].replace(\".csv\", \"_features.csv\"))\n",
    "    else:\n",
    "        stats_path = os.path.join(STATS_PATH, path.split(\"/\")[-3], path.split(\"/\")[-2], path.split(\"/\")[-1].replace(\".csv\", \"_features.csv\"))\n",
    "\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    texts = df[\"text\"].values\n",
    "\n",
    "    results, num_samples, num_sentences, num_words, num_chars, num_tokens = calc_stats(texts)\n",
    "\n",
    "    results = pd.DataFrame(results, columns=[\"num_sentences\", \"num_words\", \"num_chars\", \"num_tokens\"])\n",
    "    results.to_csv(stats_path, index=False)\n",
    "\n",
    "    data_name, model = path.split(\"/\")[-1].split(\"_\")\n",
    "    model = model.removesuffix(\".csv\")\n",
    "\n",
    "    with open(MASTER_STATS_PATH, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([data_name, model, num_samples, num_sentences, num_words, num_chars, num_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
